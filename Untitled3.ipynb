{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMIgS96o9OEt",
        "outputId": "34a7e00e-aefd-42e0-e540-0e5517120191"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv (Python 3.12.7)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/Users/anirudhkrishnakumar/Desktop/Report_analyzer_project/venv/bin/python -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch datasets numpy pandas sentence-transformers pinecone-client boto3 streamlit pinecone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zarNcvqa9snS",
        "outputId": "38fbbb0f-436b-45cd-a3c9-126add5ec139"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/t5_finetuned.zip\n",
            "replace /content/t5_finetuned/content/t5_finetuned/model.safetensors? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip /content/t5_finetuned.zip -d /content/t5_finetuned\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-J_Mi6C-bO5",
        "outputId": "d8b76256-04f0-41ed-d4d2-8a968a925cd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pinecone in /usr/local/lib/python3.11/dist-packages (7.0.0)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2025.4.26)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone) (4.13.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.4.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (2.6.0+cpu)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (0.31.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install pinecone sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAvg8LFe-syT",
        "outputId": "c39250b3-2045-4ce1-83f1-c75295ebf2ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cpu)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.31.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7caMjIj-9n4",
        "outputId": "ceb1769a-164f-4d74-ad18-40bb3524e974"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.30.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.10.1 (from gradio)\n",
            "  Downloading gradio_client-1.10.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.30.0-py3-none-any.whl (54.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.1-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.1/323.1 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading orjson-3.10.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, orjson, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.30.0 gradio-client-1.10.1 groovy-0.1.2 orjson-3.10.18 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.10 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "pZoHoJRs_CWD",
        "outputId": "eaa2006f-347b-42de-c9b0-57e588c9b9b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index financial-docs already exists. Connecting to it...\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://49f01cdeaf4cd2ccda.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://49f01cdeaf4cd2ccda.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pinecone\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize Pinecone client\n",
        "client = pinecone.Pinecone(api_key={API_KEY})\n",
        "\n",
        "# Define index name\n",
        "index_name = \"financial-docs\"\n",
        "\n",
        "# Check if the index exists; if not, create it\n",
        "if index_name not in client.list_indexes().names():\n",
        "    print(f\"Index {index_name} does not exist. Creating it...\")\n",
        "    client.create_index(\n",
        "        name=index_name,\n",
        "        dimension=384,\n",
        "        metric=\"cosine\",\n",
        "        spec=pinecone.ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
        "    )\n",
        "\n",
        "    # Connect to the index\n",
        "    index = client.Index(index_name)\n",
        "\n",
        "    # Load dataset\n",
        "    df = pd.read_csv(\"/content/financial_data.csv\")\n",
        "\n",
        "    # Load embedding model\n",
        "    embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "    # Generate embeddings\n",
        "    embeddings = embedder.encode(df[\"transcript\"].tolist(), show_progress_bar=True)\n",
        "\n",
        "    # Prepare vectors with truncated metadata\n",
        "    ids = [str(i) for i in range(len(df))]\n",
        "    vectors = [(ids[i], embeddings[i].tolist(), {\"text\": df[\"transcript\"][i][:500]}) for i in range(len(df))]\n",
        "\n",
        "    # Batch upsert\n",
        "    batch_size = 50\n",
        "    for i in range(0, len(vectors), batch_size):\n",
        "        batch = vectors[i:i + batch_size]\n",
        "        index.upsert(vectors=batch)\n",
        "        print(f\"Uploaded batch {i // batch_size + 1} of {len(vectors) // batch_size + 1}\")\n",
        "\n",
        "    print(\"Documents stored in Pinecone!\")\n",
        "else:\n",
        "    print(f\"Index {index_name} already exists. Connecting to it...\")\n",
        "    index = client.Index(index_name)\n",
        "\n",
        "# Step 4: Recreate the Gradio UI\n",
        "import gradio as gr\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# Load the embedding model\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Connect to the Pinecone index (already connected, but ensuring it's available)\n",
        "index = client.Index(\"financial-docs\")\n",
        "\n",
        "# Load the fine-tuned T5 model\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"/content/t5_finetuned/content/t5_finetuned\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"/content/t5_finetuned/content/t5_finetuned\")\n",
        "\n",
        "# Load transcript mapping\n",
        "mapping = pd.read_csv(\"/content/transcript_mapping.csv\")\n",
        "\n",
        "# Define the search and summarize function for the UI\n",
        "def search_and_summarize(query):\n",
        "    # Search Pinecone\n",
        "    query_embedding = embedder.encode([query])[0].tolist()\n",
        "    results = index.query(vector=query_embedding, top_k=1, include_metadata=True)\n",
        "\n",
        "    if not results['matches']:\n",
        "\n",
        "        return \"No matching transcripts found.\", \"\"\n",
        "\n",
        "    # Retrieve the top result\n",
        "    top_match = results['matches'][0]\n",
        "    top_id = top_match['id']\n",
        "    score = top_match['score']\n",
        "    truncated_text = top_match['metadata']['text']\n",
        "\n",
        "    # Get the full transcript using the 'mapping' DataFrame\n",
        "    matching_rows = mapping[mapping[\"pinecone_id\"].astype(str) == top_id] # Filter the mapping DataFrame\n",
        "\n",
        "    if matching_rows.empty:\n",
        "        return f\"Error: No transcript found for Pinecone ID {top_id}\", \"\"\n",
        "\n",
        "    top_transcript = matching_rows[\"transcript\"].values[0]\n",
        "\n",
        "    # Generate summary\n",
        "    inputs = tokenizer(\"summarize: \" + top_transcript, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    summary_ids = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_length=100,\n",
        "        min_length=20,\n",
        "        num_beams=6,\n",
        "        no_repeat_ngram_size=3,\n",
        "        length_penalty=1.0,\n",
        "        early_stopping=False\n",
        "    )\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    # Format the output\n",
        "    search_result = f\"**Top Matching Transcript (ID: {top_id}, Score: {score:.2f})**\\n{truncated_text}...\"\n",
        "    return search_result, summary\n",
        "\n",
        "# Build the Gradio UI\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Financial Report Summarizer\")\n",
        "    gr.Markdown(\"Enter a query to search financial transcripts and get a summary.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        query_input = gr.Textbox(label=\"Query\", placeholder=\"e.g., What is the revenue growth for Pharma?\")\n",
        "        submit_button = gr.Button(\"Search and Summarize\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            search_output = gr.Textbox(label=\"Search Result (Top Matching Transcript)\")\n",
        "        with gr.Column():\n",
        "            summary_output = gr.Textbox(label=\"Summary\")\n",
        "\n",
        "    # Connect the button to the function\n",
        "    submit_button.click(\n",
        "        fn=search_and_summarize,\n",
        "        inputs=query_input,\n",
        "        outputs=[search_output, summary_output]\n",
        "    )\n",
        "\n",
        "# Launch the UI\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "5Eg40yCYEWHc",
        "outputId": "cd47fb17-2a77-4918-dffb-c818cfe1f0b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index financial-docs already exists. Connecting to it...\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5e3dc459867fefcf71.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://5e3dc459867fefcf71.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pinecone\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Initialize Pinecone client\n",
        "client = pinecone.Pinecone(api_key=\"pcsk_3z4iTz_BoTpE3CrVJVTUvF37hWHeN5Eo6XnosKTjidbKsvb9FotdUETgUnDNpXqHkCFVN9\")\n",
        "\n",
        "# Define index name\n",
        "index_name = \"financial-docs\"\n",
        "\n",
        "# Check if the index exists; if not, create it\n",
        "if index_name not in client.list_indexes().names():\n",
        "    print(f\"Index {index_name} does not exist. Creating it...\")\n",
        "    client.create_index(\n",
        "        name=index_name,\n",
        "        dimension=384,\n",
        "        metric=\"cosine\",\n",
        "        spec=pinecone.ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
        "    )\n",
        "\n",
        "    # Connect to the index\n",
        "    index = client.Index(index_name)\n",
        "\n",
        "    # Load dataset\n",
        "    df = pd.read_csv(\"/content/financial_data.csv\")\n",
        "\n",
        "    # Load embedding model\n",
        "    embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "    # Generate embeddings\n",
        "    embeddings = embedder.encode(df[\"transcript\"].tolist(), show_progress_bar=True)\n",
        "\n",
        "    # Prepare vectors with truncated metadata\n",
        "    ids = [str(i) for i in range(len(df))]\n",
        "    vectors = [(ids[i], embeddings[i].tolist(), {\"text\": df[\"transcript\"][i][:500]}) for i in range(len(df))]\n",
        "\n",
        "    # Batch upsert\n",
        "    batch_size = 50\n",
        "    for i in range(0, len(vectors), batch_size):\n",
        "        batch = vectors[i:i + batch_size]\n",
        "        index.upsert(vectors=batch)\n",
        "        print(f\"Uploaded batch {i // batch_size + 1} of {len(vectors) // batch_size + 1}\")\n",
        "\n",
        "    print(\"Documents stored in Pinecone!\")\n",
        "else:\n",
        "    print(f\"Index {index_name} already exists. Connecting to it...\")\n",
        "    index = client.Index(index_name)\n",
        "\n",
        "# Load the embedding model\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Connect to the Pinecone index\n",
        "index = client.Index(\"financial-docs\")\n",
        "\n",
        "# Load the fine-tuned T5 model (fixed path)\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"/content/t5_finetuned/content/t5_finetuned\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"/content/t5_finetuned/content/t5_finetuned\")\n",
        "\n",
        "# Load transcript mapping\n",
        "mapping = pd.read_csv(\"/content/transcript_mapping.csv\")\n",
        "\n",
        "\n",
        "# Function to preprocess transcript and extract key financial sentences\n",
        "def preprocess_transcript(transcript):\n",
        "    # Split transcript into sentences\n",
        "    sentences = re.split(r'(?<=[.!?])\\s+', transcript)\n",
        "\n",
        "    # Keywords for financial metrics\n",
        "    financial_keywords = [\n",
        "        'revenue', 'earnings', 'eps', 'growth', 'margin', 'operating', 'profit',\n",
        "        'q1', 'q2', 'q3', 'q4', 'quarter', 'fiscal', 'year', 'outlook', 'guidance', 'market',\n",
        "        'pharma', 'chemical', 'energy', 'diagnostics', 'business unit', 'americas', 'china'\n",
        "    ]\n",
        "\n",
        "    # Filter sentences containing financial keywords\n",
        "    key_sentences = [\n",
        "        sentence for sentence in sentences\n",
        "        if any(keyword.lower() in sentence.lower() for keyword in financial_keywords)\n",
        "    ]\n",
        "\n",
        "    # Join the key sentences back into a shorter text\n",
        "    return \" \".join(key_sentences) if key_sentences else transcript\n",
        "# Updated search_and_summarize function with length parameter\n",
        "def search_and_summarize(query, summary_length):\n",
        "    try:\n",
        "        # Search Pinecone\n",
        "        query_embedding = embedder.encode([query])[0].tolist()\n",
        "        if len(query_embedding) != 384:\n",
        "            return f\"Error: Query embedding dimension ({len(query_embedding)}) does not match index dimension (384).\", \"\"\n",
        "\n",
        "        results = index.query(vector=query_embedding, top_k=1, include_metadata=True)\n",
        "        if not results['matches']:\n",
        "            return \"No matching transcripts found in Pinecone.\", \"\"\n",
        "\n",
        "        # Retrieve the top result\n",
        "        top_match = results['matches'][0]\n",
        "        top_id = top_match['id']\n",
        "        score = top_match['score']\n",
        "        truncated_text = top_match['metadata']['text']\n",
        "\n",
        "        # Ensure pinecone_id is a string in the mapping\n",
        "        mapping[\"pinecone_id\"] = mapping[\"pinecone_id\"].astype(str)\n",
        "\n",
        "        # Get the full transcript\n",
        "        matching_rows = mapping[mapping[\"pinecone_id\"] == top_id]\n",
        "        if matching_rows.empty:\n",
        "            return f\"Error: No transcript found for Pinecone ID {top_id}.\", \"\"\n",
        "\n",
        "        if \"transcript\" not in matching_rows.columns:\n",
        "            return \"Error: 'transcript' column missing in transcript_mapping.csv.\", \"\"\n",
        "\n",
        "        top_transcript = matching_rows[\"transcript\"].values[0]\n",
        "\n",
        "        # Preprocess the transcript to focus on financial details\n",
        "        processed_transcript = preprocess_transcript(top_transcript)\n",
        "\n",
        "        # Set max_length and min_length based on user selection\n",
        "        if summary_length == \"Short\":\n",
        "            max_len = 50\n",
        "            min_len = 20\n",
        "        elif summary_length == \"Medium\":\n",
        "            max_len = 200\n",
        "            min_len = 40\n",
        "        else:  # Long\n",
        "            max_len = 500\n",
        "            min_len = 60\n",
        "\n",
        "        # Generate summary\n",
        "        inputs = tokenizer(\"summarize: \" + processed_transcript, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "        summary_ids = model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            max_length=max_len,\n",
        "            min_length=min_len,\n",
        "            num_beams=6,\n",
        "            no_repeat_ngram_size=3,\n",
        "            length_penalty=2.0,\n",
        "            early_stopping=True\n",
        "        )\n",
        "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "        # Format the output\n",
        "        search_result = f\"**Top Matching Transcript (ID: {top_id}, Score: {score:.2f})**\\n{truncated_text}...\"\n",
        "        return search_result, summary\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error in search_and_summarize: {str(e)}\", \"\"\n",
        "\n",
        "# Build the Gradio UI with summary length option\n",
        "import gradio as gr\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Financial Report Summarizer\")\n",
        "    gr.Markdown(\"Enter a query to search financial transcripts and get a summary.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        query_input = gr.Textbox(label=\"Query\", placeholder=\"e.g., What is the revenue growth for Pharma?\")\n",
        "        summary_length = gr.Dropdown(\n",
        "            choices=[\"Short\", \"Medium\", \"Long\"],\n",
        "            label=\"Summary Length\",\n",
        "            value=\"Medium\"\n",
        "        )\n",
        "        submit_button = gr.Button(\"Search and Summarize\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            search_output = gr.Textbox(label=\"Search Result (Top Matching Transcript)\")\n",
        "        with gr.Column():\n",
        "            summary_output = gr.Textbox(label=\"Summary\")\n",
        "\n",
        "    # Connect the button to the function\n",
        "    submit_button.click(\n",
        "        fn=search_and_summarize,\n",
        "        inputs=[query_input, summary_length],\n",
        "        outputs=[search_output, summary_output]\n",
        "    )\n",
        "\n",
        "# Launch the UI\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        },
        "id": "CEJAGP4aN4ku",
        "outputId": "72e184af-c4ab-42e0-bca4-c743d52acd30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in transcript_mapping.csv: Index(['transcript', 'summary'], dtype='object')\n",
            "First few rows of transcript_mapping.csv:\n",
            "                                          transcript  \\\n",
            "0  Chief Investment Officer Greg Wright, Chief Te...   \n",
            "1  With me on the call is Ronald Kramer, our Chai...   \n",
            "2  These statements are based on management's cur...   \n",
            "3  I'm Susie Lisa, senior vice president of inves...   \n",
            "4  Also on the call are Brian McDade, chief finan...   \n",
            "\n",
            "                                             summary  \n",
            "0        q3 revenue rose 11 percent to $1.1 billion.  \n",
            "1  q3 earnings per share $0.31.\\nq3 adjusted earn...  \n",
            "2  q3 non-gaap earnings per share $2.55 from cont...  \n",
            "3  cvs health qtrly revenue rose 10.1% to $76.6 b...  \n",
            "4  simon property sees fy ffo per share $9.70 to ...  \n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'pinecone_id'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'pinecone_id'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-1b761f32a419>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"First few rows of transcript_mapping.csv:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pinecone_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'pinecone_id'"
          ]
        }
      ],
      "source": [
        "print(\"Columns in transcript_mapping.csv:\", df.columns)\n",
        "print(\"First few rows of transcript_mapping.csv:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybfcDlMCL2he",
        "outputId": "e54b3a79-6085-4fde-eb7f-4fb442d11342"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top transcript: More information is included in our most recent annual report on Form 10-K and subsequent quarterly reports on Form 10-Q and in the company's other filings with the SEC.\n",
            "It's a pleasure to be with you today.\n",
            "Labcorp is carrying on our mission to improve health and improve lives by harnessing the power of science, technology and innovation.\n",
            "In doing so, we're able to execute against our strategy, to deliver strong results for stakeholders and to effectively respond to global challenges like the pandemic.\n",
            "Our company rounded out a historic 2021 with another strong quarter that sets the stage for further success in 2022 and beyond.\n",
            "In the fourth quarter, revenue totaled $4.1 billion, adjusted earnings per share reached $6.77, and free cash flow was $548 million.\n",
            "For the full year, revenue was $16.1 billion, adjusted earnings per share totaled $28.52, and free cash flow reached $2.6 billion.\n",
            "Our base business continued its progress during the quarter, with diagnostics and drug development revenue growing 8.8% and 8.2%, respectively.\n",
            "In diagnostics, base business organic volume increased as esoteric and routine procedures continued their year-over-year growth.\n",
            "drug development ended the year with a solid trailing 12-month net book-to-bill of 1.25 and a strong backlog of $15 billion, representing a $579 million increase in the third quarter.\n",
            "Also decentralized clinical trial awards were up 62% over the prior year.\n",
            "Moving to the pandemic.\n",
            "Our ongoing response remains an example of how innovation can drive success.\n",
            "For nearly two years, Labcorp has dedicated significant resources to stemming the spread of the virus.\n",
            "We are proud of the progress we've made thus far, though the rise of variants like Omicron and surges in infection rates make it clear that our work is not over.\n",
            "We continue to leverage Labcorp's comprehensive capabilities to expand testing access, to identify and monitor new variants and to advance vaccine and therapy development.\n",
            "In the fourth quarter, COVID testing volumes were greater than anticipated.\n",
            "We have performed over 74 million tests for COVID to date, of which approximately 8.6 million were in the fourth quarter.\n",
            "This heightened demand continued into the new year, although volume is significantly less now than in December or in January.\n",
            "Time to results for COVID PCR test remained one to two days on average even during the latest surge.\n",
            "As we've done throughout the pandemic, we are keeping capacity levels high to quickly respond to spikes and testing needs.\n",
            "We are continuing to invest in equipment, elevated staffing levels and our supply chain.\n",
            "In addition, we remain prepared and staffed to support additional drug development work for vaccines including boosters or additional therapies.\n",
            "The company's COVID-related innovations in the quarter included the rollout of observed self-collection for COVID PCR testing at over 1,000 patient service centers.\n",
            "And at the start of the fourth quarter, we announced the receipt of FDA Emergency Use Authorization for a combined COVID and flu at-home collection kit.\n",
            "These offerings are reflective of our work to make COVID testing faster, easier and more accessible.\n",
            "I'll now turn to our enterprise strategy, where we made significant progress in 2021.\n",
            "I'll provide a few highlights that will give you a sense of our growth and our forward momentum.\n",
            "In oncology, we made significant strides in fortifying our position as a leader by expanding diagnostic offerings and clinical trial opportunities.\n",
            "At the same time, we followed through on our commitment to improve cancer care access.\n",
            "Last year, we formed our oncology business unit, and we introduced our enterprise oncology offering.\n",
            "Genomic profiling of tumors is key to identifying the best targeted therapy for oncology patients.\n",
            "In December, we announced our agreement to acquire Personal Genome diagnostics or PGDx.\n",
            "The company has a strong portfolio of innovative liquid biopsy and tissue-based products which complement our existing capabilities.\n",
            "Through PGDx' kitted solutions, we can provide oncologists access to tumor profiling at the hospitals where the patients are treated or centralized to one of our laboratories.\n",
            "These solutions may also enable us to expand tumor profiling globally to help our pharmaceutical sponsors find the right novel treatment for patients.\n",
            "We expect the transaction to close in the first quarter of this year.\n",
            "Other exciting expansions of our oncology test menu included clonoSEQ, the first and only FDA-cleared test for monitoring residual blood cancer; and OmniSeq INSIGHT, a pan-cancer tissue-based sequencing test for people with late-stage solid tumors.\n",
            "All of these offerings can help physicians make more informed decisions about treatments for their patients and help bring new medicines to market for cancer.\n",
            "In 2021, we intensified our customer focus and embedded technology and data throughout our business.\n",
            "This included improvements to the patient experience in our service centers.\n",
            "These upgrades focused on creating a seamless journey from appointment scheduling to service center visits to easier access to results.\n",
            "Our acquisition of Ovia Health enhanced our position as an important source of information for women's health which we support through diagnostic, genetic and specialty testing expertise as well as clinical trials.\n",
            "We will continue to identify opportunities to enhance Ovia Health's innovative platform that provides family planning, pregnancy and parenting support.\n",
            "Additionally, we began to deploy Labcorp Diagnostic Assistant.\n",
            "This new tool delivers a detailed view of a patient's lab history along with clinical insights directly to the point of care to inform diagnostic decisions.\n",
            "We opened an automated kit production line in Belgium in the spring.\n",
            "And in the fourth quarter, we opened an integrated laboratory in Singapore, which strengthens our bioanalytical services in the Asia Pacific region.\n",
            "And just this month, we announced the launch of Labcorp OnDemand which builds on the success of Pixel by Labcorp.\n",
            "This suite of health tests and services offers easy and convenient access to a wide variety of trusted tests.\n",
            "It's another way that Labcorp is meeting people where they are and offering more options for people to stay healthy.\n",
            "We pursued numerous opportunities throughout the year that have long-term and high-growth potential.\n",
            "We did this through tuck-in deals and strategic acquisitions including: OmniSeq, Ovia Health, PGDx, and Myriad Autoimmune's Vectra test which analyzes biomarkers to measure rheumatoid arthritis.\n",
            "Yesterday, we announced a comprehensive strategic agreement with Ascension, one of the largest health systems in the United States.\n",
            "Through our new long-term relationship with Ascension, we will manage its hospital-based laboratories in 10 states, and we will purchase select assets of its outreach laboratory business for approximately $400 million.\n",
            "We expect the first year annualized revenues to be between $550 million and $600 million from the combined hospital business and lab asset acquisition.\n",
            "While operating margins are expected to be less than segment margins initially, they are expected to improve each year.\n",
            "The transaction is expected to be accretive to our earnings and cash flow in year 1 and should return its cost of capital by year 2.\n",
            "This is a notable opportunity for us and one of the most significant deals of its kind in the sector.\n",
            "It expands our clinical services in several states across the country, and it builds on our strong track record of building similar relationships.\n",
            "The deal with Ascension also underscores our ability to help health systems manage industrywide shifts.\n",
            "As part of the collaboration, we will explore clinical trial and oncology opportunities that enhance patient access.\n",
            "We look forward to this new partnership and ultimately to welcoming new colleagues to Labcorp.\n",
            "We also reached agreements with other hospitals and hospital systems including Minnesota-based North Memorial Health.\n",
            "We continue to be excited about our robust M&A pipeline and expect more activity in the coming months.\n",
            "In 2021, we provided the highest-quality service to customers and patients, and we made meaningful investments in our people.\n",
            "In fact, Labcorp has consistently been recognized for the impact of our work and for the value we place on our employees.\n",
            "We were recently named again to Fortune magazine's list of World's Most Admired Companies.\n",
            "And for the fifth consecutive year, the Human Rights Campaign Foundation designated Labcorp as the best place to work for LGBTQ+ equality.\n",
            "We were also deemed one of America's most responsible companies for 2022 by Newsweek.\n",
            "Importantly, in 2021, management and the board of directors, working with outside advisors, thoroughly reviewed our structure and capital allocation.\n",
            "As part of the comprehensive review of our structure, we had extensive discussions with third parties, and the board considered a wide range of options including significant acquisitions, divestitures, spinning off businesses as well as spinning and merging those businesses with strategic partners.\n",
            "The board unanimously concluded that the company's existing structure is in the best interest of all stakeholders at this time.\n",
            "That said, we continue to believe that Labcorp shares are not fully valued in the marketplace.\n",
            "To that end, we announced several actions designed to further enhance shareholder value.\n",
            "Among them are the initiation of a dividend starting in the second quarter of 2022 as well as a $2.5 billion share repurchase program, $1 billion of which is being repurchased on an accelerated basis.\n",
            "We are also implementing a new LaunchPad business process improvement initiative that targets $350 million in savings over the next three years.\n",
            "And today, in addition to giving 2022 guidance, we will also share a longer-term outlook.\n",
            "And beginning with first quarter results, we will provide additional business insights through enhanced disclosures.\n",
            "Moving forward, we are committed to profitable growth through investments in science, innovation and new technology.\n",
            "As we execute on our strategy, management and board will continue to evaluate all avenues for enhancing shareholder value.\n",
            "In conclusion, our strong base business performance, coupled with formidable progress against our strategic priorities in 2021, sets us up for long-term success.\n",
            "This gives us great confidence in our longer-term, growth-oriented, bright outlook which Glenn will take you through, along with our 2022 guidance.\n",
            "I am proud of what the team at Labcorp accomplished together in 2021, and I am excited for all that's to come this year and into the future as we continue to deliver for all of our stakeholders.\n",
            "I'm going to start my comments with a review of our fourth quarter results, followed by a discussion of our performance in each segment, our 2022 full year guidance and then conclude with our longer-term outlook through 2024.\n",
            "Revenue for the quarter was $4.1 billion, a decrease of 9.7% compared to last year due to declines in organic revenue of 10.3% and divestitures of 0.1%, partially offset by acquisitions of 0.6% and favorable foreign currency translation of 10 basis points.\n",
            "The 10.3% decline in organic revenue was driven by a 15.3% decrease in COVID testing, partially offset by a 5% increase in the company's organic base business.\n",
            "Operating income for the quarter was $731 million or 18% of revenue.\n",
            "During the quarter, we had $93 million of amortization and $79 million of restructuring charges and special items.\n",
            "Excluding these items, adjusted operating income in the quarter was $902 million or 22.2% of revenue compared to $1.4 billion or 31.8% last year.\n",
            "The decrease in adjusted operating income and margin was due to a reduction in COVID testing.\n",
            "Excluding COVID testing, the base business compared to the base business last year experienced higher adjusted operating income and margins due to organic growth and LaunchPad savings, partially offset by higher personnel costs.\n",
            "The tax rate for the quarter was 19.3%.\n",
            "The adjusted tax rate excluding restructuring charges, special items and amortization, was 24.6% compared to 24.8% last year.\n",
            "Going forward, we continue to expect the adjusted tax rate to be approximately 25% excluding any impact from potential tax reform.\n",
            "Net earnings for the quarter were $553 million or $5.75 per diluted share.\n",
            "Adjusted earnings per share which exclude amortization, restructuring charges and special items, were $6.77 in the quarter, down from $10.56 last year.\n",
            "Operating cash flow was $698 million in the quarter compared to $775 million a year ago.\n",
            "The decrease in operating cash flow was due to lower cash earnings, partially offset by favorable working capital.\n",
            "Capital expenditures totaled $150 million compared to $99 million last year.\n",
            "And as a result, free cash flow was $548 million in the quarter compared to $675 million last year.\n",
            "During the quarter, we used $1 billion of our cash flow for our accelerated share repurchase program and invested $171 million on acquisitions.\n",
            "Now, I'll review our segment performance, beginning with diagnostics.\n",
            "Revenue for the quarter was $2.6 billion, a decrease of 16.9% compared to last year due to organic revenue being down 17.8%, partially offset by acquisitions of 0.7% and favorable foreign currency translation of 20 basis points.\n",
            "The decrease in organic revenue was due to a 21.8% reduction from COVID testing partially offset by a 4.1% increase in the base business.\n",
            "Relative to the fourth quarter of 2019, the compound annual growth rate for the base business revenue was 5% primarily due to organic growth.\n",
            "Total volume decreased 8.7% compared to last year as organic volume decreased by 8.9% partially offset by acquisition volume of 0.3%.\n",
            "The decrease in organic volume was due to a 14.6% decline in COVID testing partially offset by a 5.7% increase in the base business.\n",
            "Price mix decreased 8.2% versus last year due to lower COVID testing of 7.2% and lower base business of 1.6% partially offset by acquisitions of 0.5% and currency of 0.2%.\n",
            "Diagnostics organic base business revenue growth was 7.2% compared to its base business last year, with 8.1% coming from volume, partially offset by a 1% decline from price mix.\n",
            "The price mix decline was primarily due to the recovery of our Canadian business which carries a lower average requisition price.\n",
            "diagnostics adjusted operating income for the quarter was $776 million or 29.6% of revenue compared to $1.2 billion or 39.1% last year.\n",
            "The decrease in adjusted operating income and margin was due to a reduction in COVID testing.\n",
            "COVID testing margins were down compared to last year primarily due to a volume decline of approximately 50%, while the company continued to maintain capacity.\n",
            "base business margins were higher compared to last year due to organic base business growth and LaunchPad savings partially offset by higher personnel costs.\n",
            "diagnostics achieved its goal to deliver approximately $200 million of net savings from its three-year LaunchPad initiative.\n",
            "Now, I'll review the performance of drug development.\n",
            "Revenue for the quarter was $1.5 billion, an increase of 3.9% compared to last year due to organic base business growth of 7.9% and acquisitions of 0.3%, partially offset by lower COVID testing performed through its centralized business of 4% and divestitures of 0.3%.\n",
            "Relative to the fourth quarter of 2019, the compound annual growth rate for base business revenue was 9.9% primarily driven by organic growth.\n",
            "Adjusted operating income for the segment was $206 million or 14.2% of revenue compared to $248 million or 17.8% last year.\n",
            "The decrease in adjusted operating income and margin was primarily due to lower COVID testing.\n",
            "In the base business, higher personnel and other inflationary costs as well as investments in oncology capabilities were partially offset by organic growth and LaunchPad savings.\n",
            "We continue to exclude the enterprise component of drug development bonus expense which is reflected in corporate unallocated and totaled $11 million for the quarter.\n",
            "While margins were down in the quarter, they were up for the full year compared to 2020, and we expect margins to continue to increase in 2022.\n",
            "For the trailing 12 months, net orders and net book-to-bill remained strong at $7.3 billion and 1.25, respectively.\n",
            "Backlog at the end of the quarter was $15 billion, an increase of 8.7% compared to last year.\n",
            "And we expect approximately $5 billion of this backlog to convert into revenue over the next 12 months.\n",
            "Now, I'll discuss our 2022 guidance which assumes foreign exchange rates effective as of December 31, 2021, for the full year.\n",
            "In addition, the guidance includes the softness we experienced in January due to Omicron which we expect will rebound through the rest of the quarter.\n",
            "The enterprise guidance also includes the impact from currently anticipated capital allocation, with free cash flow targeted to acquisitions, share repurchases and dividends which we will initiate in the second quarter.\n",
            "We expect enterprise revenue to decline one and a half to six and a half percent compared to 2021.\n",
            "This guidance range includes the expectation that the base business will grow seven and a half to 10%, while COVID testing is expected to decline 60% to 75%.\n",
            "We expect diagnostics revenue to decline 11 and a half to 17 and a half percent compared to 2021.\n",
            "This guidance range includes the expectation that the base business will growth three and a half to 6%.\n",
            "COVID testing revenue is expected to decline 60% to 75%.\n",
            "At the midpoint of our base business guidance range, the compound annual growth rate compared to 2019 would be 4.4% primarily driven by organic growth in both volume and price mix.\n",
            "We expect drug development revenue to grow 7% to 9.5% compared to 2021.\n",
            "This guidance includes the negative impact from foreign currency translation of 40 basis points.\n",
            "This guidance range also includes the expectation that the base business will grow seven and a half to 10% compared to 2021.\n",
            "Given the amount of capacity we have within diagnostics, we've assumed that no COVID testing will be performed in drug development central lab business in 2022.\n",
            "We expect to benefit from broad-based growth in all three businesses, helping drive continued margin improvement in the segment.\n",
            "At the midpoint of our base business guidance range, the compound annual growth rate compared to 2019 would be 11.3%.\n",
            "Our adjusted earnings per share guidance is $17.25 to $21.25 compared to 2021 adjusted earnings per share of $28.52.\n",
            "The adjusted earnings per share guidance reflects the expectation of lower COVID testing in 2022, while the base business continues to profitably grow.\n",
            "Free cash flow is expected to be between $1.7 billion to $1.9 billion compared to $2.6 billion in 2021.\n",
            "Now, I'll discuss our longer-term outlook which reflects our current view of the business from 2022 to 2024.\n",
            "We expect enterprise base business organic revenue to grow at a compound annual growth rate of 4% to 7% compared to 2021.\n",
            "We also expect revenue growth from acquisitions to represent additional annual growth of 2% to 3%.\n",
            "We expect diagnostics base business organic revenue to grow at a two and a half to four and a half percent CAGR compared to 2021.\n",
            "This outlook is higher than historical growth driven by a continued recovery in our base business relative to 2021, broad-based growth including hospitals and health systems and the lower incremental impact of PAMA in the outlook period.\n",
            "We expect drug development base business organic revenue to grow at a 7% to 10% CAGR compared to 2021.\n",
            "This outlook is higher than our historical growth, and we have added capacity and inorganic investments in the last few years in our faster-growing early development and late-stage clinical businesses.\n",
            "As we continue to emphasize profitable growth, we expect enterprise margin expansion of 30 to 50 basis points on average annually through the outlook period compared to 2021 which was approximately 14 and a half percent.\n",
            "This margin expansion is due in part to the company's LaunchPad initiative which is expected to deliver $350 million of cost savings over the time period to help offset inflationary costs.\n",
            "And finally, we expect adjusted earnings per share to grow at an 11% to 14% CAGR compared to 2020 -- '19 adjusted earnings per share of $11.32.\n",
            "We continue to use 2019 as the base year comparison for earnings growth to better reflect the earnings power of the company excluding COVID testing.\n",
            "The adjusted earnings per share outlook reflects the expectation that both base businesses will continue to profitably grow organically.\n",
            "In addition, we expect to benefit from capital allocation directed toward accretive acquisitions and share repurchases while keeping within our targeted gross debt leverage of two and a half to three times.\n",
            "For additional comparison purposes, we've also included in the supplemental deck on our investor relations website a view of 2021 fourth quarter and full year results, 2022 guidance and our longer-term outlook.\n",
            "In summary, the company had another quarter of strong performance.\n",
            "We remain focused on performing a critical role in response to the global pandemic while also growing our base business.\n",
            "For 2022, we expect to drive continued profitable growth in our base business, while COVID testing volumes are expected to decline through the year.\n",
            "In addition, our longer-term outlook is expected to deliver double-digit adjusted earnings per share growth driven by top-line growth, margin improvement and capital allocation.\n",
            "Operator, we'll now take questions.\n"
          ]
        }
      ],
      "source": [
        "mapping[\"pinecone_id\"] = mapping[\"pinecone_id\"].astype(str)\n",
        "matching_row = mapping[mapping[\"pinecone_id\"] == top_id]\n",
        "if matching_row.empty:c\n",
        "    print(\"No matching transcript found for ID:\", top_id)\n",
        "else:\n",
        "    top_transcript = matching_row[\"transcript\"].values[0]\n",
        "    print(\"Top transcript:\", top_transcript)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d1900b43caeb4304bd7a77d9ea26bf0a",
            "7a852405cb9a4798a75cabf43aa1dab3",
            "c3a43c4ea1374a9bad3b3c311ab48778",
            "e9695d9c2d49410b9a69fed589f28aba",
            "8f75f7643252428ba2f81f2f405d453c",
            "002a2d501d174a6f82bb6c12932f27cf",
            "5ccc70176ee741fbaf68d09411b86bef",
            "375b00ed46984e7fb26751a8b718c0db",
            "bb692c68aff243bd98946d5056a977f9",
            "a885f8682d3c4309ba7c27e9b466eded",
            "c4e168535e87402f9ee61052c27a664a"
          ]
        },
        "id": "u2bSqRq7hML7",
        "outputId": "ad91fb9c-c06a-4e21-b678-090fc8ce81a7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1900b43caeb4304bd7a77d9ea26bf0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/76 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uploaded batch 1 of 49\n",
            "Uploaded batch 2 of 49\n",
            "Uploaded batch 3 of 49\n",
            "Uploaded batch 4 of 49\n",
            "Uploaded batch 5 of 49\n",
            "Uploaded batch 6 of 49\n",
            "Uploaded batch 7 of 49\n",
            "Uploaded batch 8 of 49\n",
            "Uploaded batch 9 of 49\n",
            "Uploaded batch 10 of 49\n",
            "Uploaded batch 11 of 49\n",
            "Uploaded batch 12 of 49\n",
            "Uploaded batch 13 of 49\n",
            "Uploaded batch 14 of 49\n",
            "Uploaded batch 15 of 49\n",
            "Uploaded batch 16 of 49\n",
            "Uploaded batch 17 of 49\n",
            "Uploaded batch 18 of 49\n",
            "Uploaded batch 19 of 49\n",
            "Uploaded batch 20 of 49\n",
            "Uploaded batch 21 of 49\n",
            "Uploaded batch 22 of 49\n",
            "Uploaded batch 23 of 49\n",
            "Uploaded batch 24 of 49\n",
            "Uploaded batch 25 of 49\n",
            "Uploaded batch 26 of 49\n",
            "Uploaded batch 27 of 49\n",
            "Uploaded batch 28 of 49\n",
            "Uploaded batch 29 of 49\n",
            "Uploaded batch 30 of 49\n",
            "Uploaded batch 31 of 49\n",
            "Uploaded batch 32 of 49\n",
            "Uploaded batch 33 of 49\n",
            "Uploaded batch 34 of 49\n",
            "Uploaded batch 35 of 49\n",
            "Uploaded batch 36 of 49\n",
            "Uploaded batch 37 of 49\n",
            "Uploaded batch 38 of 49\n",
            "Uploaded batch 39 of 49\n",
            "Uploaded batch 40 of 49\n",
            "Uploaded batch 41 of 49\n",
            "Uploaded batch 42 of 49\n",
            "Uploaded batch 43 of 49\n",
            "Uploaded batch 44 of 49\n",
            "Uploaded batch 45 of 49\n",
            "Uploaded batch 46 of 49\n",
            "Uploaded batch 47 of 49\n",
            "Uploaded batch 48 of 49\n",
            "Uploaded batch 49 of 49\n",
            "Documents stored in Pinecone!\n",
            "Transcript mapping saved to /content/transcript_mapping.csv\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Transcript mapping copied to Google Drive!\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.30.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.10)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f615817e-4623-4142-b247-8eaeed08bb5e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f615817e-4623-4142-b247-8eaeed08bb5e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/t5_finetuned.zip\n",
            "replace /content/content/t5_finetuned/model.safetensors? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace /content/content/t5_finetuned/spiece.model? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace /content/content/t5_finetuned/generation_config.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace /content/content/t5_finetuned/added_tokens.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace /content/content/t5_finetuned/tokenizer_config.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace /content/content/t5_finetuned/config.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace /content/content/t5_finetuned/special_tokens_map.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        },
        {
          "ename": "HFValidationError",
          "evalue": "Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/content/t5_finetuned'. Use `repo_type` argument if needed.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# This is slightly better for only 1 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             hf_hub_download(\n\u001b[0m\u001b[1;32m    425\u001b[0m                 \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepo_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;34m\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/content/t5_finetuned'. Use `repo_type` argument if needed.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-49629f66fc7a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m# Load the fine-tuned T5 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5Tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/t5_finetuned\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5ForConditionalGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/t5_finetuned\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1986\u001b[0m                     \u001b[0;31m# Try to get the tokenizer config to see if there are versioned tokenizer files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1987\u001b[0m                     \u001b[0mfast_tokenizer_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFULL_TOKENIZER_FILE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1988\u001b[0;31m                     resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m   1989\u001b[0m                         \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1990\u001b[0m                         \u001b[0mTOKENIZER_CONFIG_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \"\"\"\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;31m# Now we try to recover if we can find all files correctly in the cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         resolved_files = [\n\u001b[0m\u001b[1;32m    471\u001b[0m             \u001b[0m_get_cache_file_to_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfull_filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         ]\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;31m# Now we try to recover if we can find all files correctly in the cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         resolved_files = [\n\u001b[0;32m--> 471\u001b[0;31m             \u001b[0m_get_cache_file_to_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfull_filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m         ]\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresolved_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36m_get_cache_file_to_return\u001b[0;34m(path_or_repo_id, full_filename, cache_dir, revision)\u001b[0m\n\u001b[1;32m    132\u001b[0m ):\n\u001b[1;32m    133\u001b[0m     \u001b[0;31m# We try to see if we have a cached version (not up to date):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0mresolved_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtry_to_load_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresolved_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresolved_file\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_CACHED_NO_EXIST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresolved_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m         ):\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"token\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marg_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepo_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;34m\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;34mf\" '{repo_id}'. Use `repo_type` argument if needed.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/content/t5_finetuned'. Use `repo_type` argument if needed."
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pinecone\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize Pinecone client\n",
        "client = pinecone.Pinecone(api_key=\"pcsk_3z4iTz_BoTpE3CrVJVTUvF37hWHeN5Eo6XnosKTjidbKsvb9FotdUETgUnDNpXqHkCFVN9\")\n",
        "\n",
        "# Define index name\n",
        "index_name = \"financial-docs\"\n",
        "\n",
        "# Create index if it doesn't exist\n",
        "if index_name not in client.list_indexes().names():\n",
        "    client.create_index(\n",
        "        name=index_name,\n",
        "        dimension=384,\n",
        "        metric=\"cosine\",\n",
        "        spec=pinecone.ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
        "    )\n",
        "\n",
        "# Connect to the index\n",
        "index = client.Index(index_name)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/financial_data.csv\")\n",
        "\n",
        "# Load embedding model\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Generate embeddings\n",
        "embeddings = embedder.encode(df[\"transcript\"].tolist(), show_progress_bar=True)\n",
        "\n",
        "# Prepare vectors with truncated metadata\n",
        "ids = [str(i) for i in range(len(df))]\n",
        "vectors = [(ids[i], embeddings[i].tolist(), {\"text\": df[\"transcript\"][i][:500]}) for i in range(len(df))]\n",
        "\n",
        "# Batch upsert\n",
        "batch_size = 50\n",
        "for i in range(0, len(vectors), batch_size):\n",
        "    batch = vectors[i:i + batch_size]\n",
        "    index.upsert(vectors=batch)\n",
        "    print(f\"Uploaded batch {i // batch_size + 1} of {len(vectors) // batch_size + 1}\")\n",
        "\n",
        "print(\"Documents stored in Pinecone!\")\n",
        "\n",
        "# Save transcript mapping\n",
        "df[\"pinecone_id\"] = ids\n",
        "df[[\"pinecone_id\", \"transcript\"]].to_csv(\"/content/transcript_mapping.csv\", index=False)\n",
        "print(\"Transcript mapping saved to /content/transcript_mapping.csv\")\n",
        "\n",
        "# # Save to Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# !cp /content/transcript_mapping.csv /content/drive/MyDrive/transcript_mapping.csv\n",
        "# print(\"Transcript mapping copied to Google Drive!\")\n",
        "\n",
        "# # Install Gradio\n",
        "# !pip install gradio\n",
        "\n",
        "# # Re-upload the fine-tuned T5 model\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()  # Upload t5_finetuned.zip\n",
        "# !unzip /content/t5_finetuned.zip -d /content\n",
        "\n",
        "# # Import necessary libraries for the UI\n",
        "# import gradio as gr\n",
        "# from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# # Load the embedding model (already loaded, but ensuring it's available)\n",
        "# embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# # Connect to the Pinecone index (already connected, but ensuring it's available)\n",
        "# index = client.Index(\"financial-docs\")\n",
        "\n",
        "# # Load the fine-tuned T5 model\n",
        "# tokenizer = T5Tokenizer.from_pretrained(\"/content/t5_finetuned\")\n",
        "# model = T5ForConditionalGeneration.from_pretrained(\"/content/t5_finetuned\")\n",
        "\n",
        "# # Load transcript mapping\n",
        "# mapping = pd.read_csv(\"/content/transcript_mapping.csv\")\n",
        "\n",
        "# # Define the search and summarize function for the UI\n",
        "# def search_and_summarize(query):\n",
        "#     # Search Pinecone\n",
        "#     query_embedding = embedder.encode([query])[0].tolist()\n",
        "#     results = index.query(vector=query_embedding, top_k=1, include_metadata=True)\n",
        "\n",
        "#     if not results['matches']:\n",
        "#         return \"No matching transcripts found.\", \"\"\n",
        "\n",
        "#     # Retrieve the top result\n",
        "#     top_match = results['matches'][0]\n",
        "#     top_id = top_match['id']\n",
        "#     score = top_match['score']\n",
        "#     truncated_text = top_match['metadata']['text']\n",
        "\n",
        "    # Get the full transcript\n",
        "#     top_transcript = mapping[mapping[\"pinecone_id\"] == top_id][\"transcript\"].values[0]\n",
        "\n",
        "#     # Generate summary\n",
        "#     inputs = tokenizer(\"summarize: \" + top_transcript, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "#     summary_ids = model.generate(\n",
        "#         inputs[\"input_ids\"],\n",
        "#         max_length=100,\n",
        "#         min_length=20,\n",
        "#         num_beams=6,\n",
        "#         no_repeat_ngram_size=3,\n",
        "#         length_penalty=1.0,\n",
        "#         early_stopping=False\n",
        "#     )\n",
        "#     summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "#     # Format the output\n",
        "#     search_result = f\"**Top Matching Transcript (ID: {top_id}, Score: {score:.2f})**\\n{truncated_text}...\"\n",
        "#     return search_result, summary\n",
        "\n",
        "# # Build the Gradio UI\n",
        "# with gr.Blocks() as demo:\n",
        "#     gr.Markdown(\"# Financial Report Summarizer\")\n",
        "#     gr.Markdown(\"Enter a query to search financial transcripts and get a summary.\")\n",
        "\n",
        "#     with gr.Row():\n",
        "#         query_input = gr.Textbox(label=\"Query\", placeholder=\"e.g., What is the revenue growth for Pharma?\")\n",
        "#         submit_button = gr.Button(\"Search and Summarize\")\n",
        "\n",
        "#     with gr.Row():\n",
        "#         with gr.Column():\n",
        "#             search_output = gr.Textbox(label=\"Search Result (Top Matching Transcript)\")\n",
        "#         with gr.Column():\n",
        "#             summary_output = gr.Textbox(label=\"Summary\")\n",
        "\n",
        "#     # Connect the button to the function\n",
        "#     submit_button.click(\n",
        "#         fn=search_and_summarize,\n",
        "#         inputs=query_input,\n",
        "#         outputs=[search_output, summary_output]\n",
        "#     )\n",
        "\n",
        "# # Launch the UI\n",
        "# demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvG12KxMvn0I",
        "outputId": "5a51b8eb-b368-4e84-e56e-872b7258e507"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unzipped to /content/data\n",
            "final  __MACOSX\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define the path to your ZIP file\n",
        "zip_path = \"/content/final.zip\"\n",
        "\n",
        "# Define where to extract the files\n",
        "extract_path = \"/content/data\"\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"Unzipped to {extract_path}\")\n",
        "\n",
        "# List the extracted files to confirm\n",
        "!ls {extract_path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU1DwTsU9XCr",
        "outputId": "4e489b69-54a6-42e3-8a91-57cb6a5b4153"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created financial_data.csv with 2425 transcript-summary pairs!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define paths to the folders\n",
        "ects_path = \"/content/data/final/\"\n",
        "summaries_path = \"/content/data/final/\"\n",
        "\n",
        "# Lists to store transcripts and summaries\n",
        "transcripts = []\n",
        "summaries = []\n",
        "lis_folders = [\"test\", \"train\", \"val\"]\n",
        "# Get list of files in ects folder\n",
        "for folder in lis_folders:\n",
        "  transcript_files = [f for f in os.listdir(ects_path + folder + \"/ects\") if f.endswith(\".txt\")]\n",
        "\n",
        "  # For each transcript file, find its matching summary file\n",
        "  for transcript_file in transcript_files:\n",
        "      # Read the transcript\n",
        "      with open(os.path.join(ects_path + folder + \"/ects\", transcript_file), \"r\", encoding=\"utf-8\") as f:\n",
        "          transcript_text = f.read().strip()\n",
        "\n",
        "      # Look for the matching summary file (same filename)\n",
        "      summary_file = os.path.join(summaries_path + folder + \"/gt_summaries\", transcript_file)\n",
        "      if os.path.exists(summary_file):\n",
        "          with open(summary_file, \"r\", encoding=\"utf-8\") as f:\n",
        "              summary_text = f.read().strip()\n",
        "\n",
        "          # Add the pair to our lists\n",
        "          transcripts.append(transcript_text)\n",
        "          summaries.append(summary_text)\n",
        "      else:\n",
        "          print(f\"Warning: No matching summary found for {transcript_file}\")\n",
        "\n",
        "# Create a DataFrame\n",
        "data = {\n",
        "    \"transcript\": transcripts,\n",
        "    \"summary\": summaries\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv(\"financial_data.csv\", index=False)\n",
        "print(f\"Created financial_data.csv with {len(df)} transcript-summary pairs!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGrG5EaoDXhX"
      },
      "source": [
        "Check whether the data was successfully transformed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvcJAGHTxgm3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/financial_data.csv\")\n",
        "\n",
        "# Check the number of samples\n",
        "print(f\"Number of samples: {len(df)}\")\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(df.head(1)['transcript'])\n",
        "test1 = df.head(1)['transcript']\n",
        "test2 = df.head(1)['summary']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VFOlx9MxggE"
      },
      "outputs": [],
      "source": [
        "# Use a subset of 500 samples for testing\n",
        "df_subset = df.head(500)\n",
        "\n",
        "# Save the subset to a new CSV\n",
        "df_subset.to_csv(\"/content/financial_data_subset.csv\", index=False)\n",
        "print(\"Created financial_data_subset.csv with 500 samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5VDbmUfU5Bo"
      },
      "outputs": [],
      "source": [
        "# Now try importing the T5 model\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
        "print(\"T5 model loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b216605498c44c1880248d49bcefb89d",
            "0b8202da2ff342e18a57951572e0a39e",
            "9b25a1bd9ae74451ae8951050f39cb85",
            "020a95734a674ecfbe47de1335328ec1",
            "5cbdd6142aed47079f8dd02d9dc00d23",
            "d84f667aca6c4179a930fb24b00269e3",
            "bea016d468ff4c9da7303715fc9588f1",
            "beac7e6851de425d8f57b01118bd90e5",
            "f7967e664c6d4fc6ae879a7d9d93e2b0",
            "5bc53d7259764f7abf914cebb67f4080",
            "7d1982fa1e96406e9d7ea7f1be67bb73",
            "5939590b59134f569060788988cfcee9",
            "7d5ff926ae3a48cfb07dba6827c37507",
            "68b2fb4065464eabb7d7e07788ac7380",
            "694a0256fe694f76b972d6459e04b89b",
            "3e42d7bf9c6f414285abe2fe38ba8cfc",
            "6fb18fb7c3a34d7383327144ddeeaaec",
            "8b8176b0bd354f3c95909cbced7a828c",
            "65560493d0894132b745be466c6a2448",
            "6fb430591ae44dcd948849f1f13111a6",
            "7e150f0f362949cf8be29d44d10f7fc0",
            "2f5a653a51644a1cbb6c1f93a447e577",
            "7e02f25143c54537bd29cb58533b5d99",
            "8927e90352bd4ad38340f87935c4cf7f",
            "bc161ecdfc814da38eb75dadc8566230",
            "a289b33a66dc4081a4e4b2b17dda98e6",
            "80291b0e9eb64287a4b97679126c2471",
            "fd073a9d053e43a0a88c337e3927a232",
            "91b8e9dc648341a9b14da39d33942a27",
            "9276d0baa80b48e19a775b1467044e88",
            "12032e37d36242808f6960223de2510e",
            "038603815d674f77ac694a9bd462d5a1",
            "1af5466dc6994369922e64e8dff9f2c9",
            "5672569e3eff4e708e493045eda1949b",
            "dbc06cefa88e4a968c2b0ec9a9841cae",
            "78b45f2094034f20876e2d771240a500",
            "a91d0926579945a6897ab6fd1da0e290",
            "09793013b5474f679e781f7a7b574c79",
            "aaa5140041a9414a9c1fe1ce91ba298a",
            "fad68e9a9d004e30aed551a0aea7f66d",
            "950c4769e85243749b0c50cfae371eba",
            "9f0351c77b994a75a40fd0e704939ed7",
            "f7eec62138654512b041ab2ef917deaf",
            "fd45b722101340768dac9f7106b301b9",
            "cd80f4ada5ae4e2baa5b3d6154c09f66",
            "dc10fe5f3326447fb9e742d44912f086",
            "53e13e7815d94c34b579e8568e6375c0",
            "fe404c2bf46e4327895d401114a89294",
            "3bad5d0c59804481bfd7cf1b29f3129a",
            "90588558ea724f4590939d4e3722bc65",
            "308f57eb67ff485789982a5b8e5946de",
            "f83002e813f94a16b58e49d2e0d33eb7",
            "e473108aa2fa4bbc8a7b7c1452e0a299",
            "b0771b9a98bb408bb30f54066160c1f5",
            "1ca6a08f443d4539b56c7f341f040695",
            "17f054ad311d47e3acd0d7502466ede5",
            "2b2ab8e1ec8748158c44f667ec561a13",
            "ed63cadc2bd24f2a830710a28b1eb22c",
            "963301adba1e435491fd35994f65654a",
            "d1a54dd2fd074a74b1c8710db2db3b69",
            "d8f05ef6ab454921ba0fb3f155ad2465",
            "f14a8378ab87457086fe2f4a7861a110",
            "d270f09a384c4b63b17bec9281cc57a3",
            "1611b5cb7d52425b9bc6beb0969adf2f",
            "156b8c7a82e74fe0b4368e761df79982",
            "c459955c82774374bd6f924dccfb044e",
            "edd94167ca484b5baa93d3e272f92141",
            "08632020ac154eeea23e170454e0b959",
            "9fd4862163c843989eaa8b38e6042c3e",
            "1f144892695c488e938599a88cb83fb7",
            "fb8cf0da2a11411ba4d082817e32034c",
            "021b14a88fb5447c932533c03b0b3d3f",
            "66b417870da6439ba2fafcc3c66551a9",
            "a3211feee5e04bc2af90fcc76a5ca338",
            "b369329812b145fbad34b0e3a00720cd",
            "221b34f6645f4c008cab14c512f6f2df",
            "03562f72b92e426b9c839e41e16724a1"
          ]
        },
        "id": "X_egv2OCxtIa",
        "outputId": "8c22df7b-e241-4055-d8c3-fc0755aaa60e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b216605498c44c1880248d49bcefb89d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5939590b59134f569060788988cfcee9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e02f25143c54537bd29cb58533b5d99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5672569e3eff4e708e493045eda1949b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd80f4ada5ae4e2baa5b3d6154c09f66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17f054ad311d47e3acd0d7502466ede5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edd94167ca484b5baa93d3e272f92141",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2425 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbluefoodgames\u001b[0m (\u001b[33mbluefoodgames-univeristy-of-minnesota\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250520_014848-dtn6552m</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/bluefoodgames-univeristy-of-minnesota/huggingface/runs/dtn6552m' target=\"_blank\">/content/t5_finetuned</a></strong> to <a href='https://wandb.ai/bluefoodgames-univeristy-of-minnesota/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/bluefoodgames-univeristy-of-minnesota/huggingface' target=\"_blank\">https://wandb.ai/bluefoodgames-univeristy-of-minnesota/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/bluefoodgames-univeristy-of-minnesota/huggingface/runs/dtn6552m' target=\"_blank\">https://wandb.ai/bluefoodgames-univeristy-of-minnesota/huggingface/runs/dtn6552m</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2910' max='2910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2910/2910 08:05, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.705500</td>\n",
              "      <td>1.437874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.488000</td>\n",
              "      <td>1.331870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.343800</td>\n",
              "      <td>1.311662</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model fine-tuned and saved!\n",
            "  adding: content/t5_finetuned/ (stored 0%)\n",
            "  adding: content/t5_finetuned/model.safetensors (deflated 10%)\n",
            "  adding: content/t5_finetuned/spiece.model (deflated 48%)\n",
            "  adding: content/t5_finetuned/generation_config.json (deflated 29%)\n",
            "  adding: content/t5_finetuned/checkpoint-970/ (stored 0%)\n",
            "  adding: content/t5_finetuned/checkpoint-970/model.safetensors (deflated 11%)\n",
            "  adding: content/t5_finetuned/checkpoint-970/rng_state.pth (deflated 25%)\n",
            "  adding: content/t5_finetuned/checkpoint-970/generation_config.json (deflated 29%)\n",
            "  adding: content/t5_finetuned/checkpoint-970/optimizer.pt (deflated 7%)\n",
            "  adding: content/t5_finetuned/checkpoint-970/config.json (deflated 63%)\n",
            "  adding: content/t5_finetuned/checkpoint-970/scheduler.pt (deflated 55%)\n",
            "  adding: content/t5_finetuned/checkpoint-970/trainer_state.json (deflated 68%)\n",
            "  adding: content/t5_finetuned/checkpoint-970/training_args.bin (deflated 52%)\n",
            "  adding: content/t5_finetuned/added_tokens.json (deflated 83%)\n",
            "  adding: content/t5_finetuned/tokenizer_config.json (deflated 94%)\n",
            "  adding: content/t5_finetuned/config.json (deflated 63%)\n",
            "  adding: content/t5_finetuned/checkpoint-2910/ (stored 0%)\n",
            "  adding: content/t5_finetuned/checkpoint-2910/model.safetensors (deflated 10%)\n",
            "  adding: content/t5_finetuned/checkpoint-2910/rng_state.pth (deflated 25%)\n",
            "  adding: content/t5_finetuned/checkpoint-2910/generation_config.json (deflated 29%)\n",
            "  adding: content/t5_finetuned/checkpoint-2910/optimizer.pt (deflated 7%)\n",
            "  adding: content/t5_finetuned/checkpoint-2910/config.json (deflated 63%)\n",
            "  adding: content/t5_finetuned/checkpoint-2910/scheduler.pt (deflated 56%)\n",
            "  adding: content/t5_finetuned/checkpoint-2910/trainer_state.json (deflated 75%)\n",
            "  adding: content/t5_finetuned/checkpoint-2910/training_args.bin (deflated 52%)\n",
            "  adding: content/t5_finetuned/checkpoint-1940/ (stored 0%)\n",
            "  adding: content/t5_finetuned/checkpoint-1940/model.safetensors (deflated 10%)\n",
            "  adding: content/t5_finetuned/checkpoint-1940/rng_state.pth (deflated 25%)\n",
            "  adding: content/t5_finetuned/checkpoint-1940/generation_config.json (deflated 29%)\n",
            "  adding: content/t5_finetuned/checkpoint-1940/optimizer.pt (deflated 7%)\n",
            "  adding: content/t5_finetuned/checkpoint-1940/config.json (deflated 63%)\n",
            "  adding: content/t5_finetuned/checkpoint-1940/scheduler.pt (deflated 56%)\n",
            "  adding: content/t5_finetuned/checkpoint-1940/trainer_state.json (deflated 73%)\n",
            "  adding: content/t5_finetuned/checkpoint-1940/training_args.bin (deflated 52%)\n",
            "  adding: content/t5_finetuned/special_tokens_map.json (deflated 85%)\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_1a48cb07-5d71-42c0-b4fb-0797dedc727a\", \"t5_finetuned.zip\", 2221234832)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset with pandas\n",
        "df = pd.read_csv(\"/content/financial_data.csv\")\n",
        "\n",
        "# Convert pandas DataFrame to a Hugging Face Dataset\n",
        "dataset = Dataset.from_pandas(df)\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "\n",
        "# Preprocess data: Add \"summarize: \" prefix to inputs\n",
        "def preprocess_function(examples):\n",
        "    inputs = [\"summarize: \" + doc for doc in examples[\"transcript\"]]\n",
        "    targets = examples[\"summary\"]\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
        "    labels = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\")\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# Apply preprocessing\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Split into train/test (80% train, 20% test)\n",
        "train_size = int(0.8 * len(tokenized_dataset))\n",
        "train_dataset = tokenized_dataset.select(range(train_size))\n",
        "eval_dataset = tokenized_dataset.select(range(train_size, len(tokenized_dataset)))\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/t5_finetuned\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=1,  # Keep batch size low to avoid memory issues\n",
        "    per_device_eval_batch_size=1,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"/content/logs\",\n",
        "    logging_steps=100,\n",
        "    gradient_accumulation_steps=2,\n",
        ")\n",
        "\n",
        "# Initialize trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        ")\n",
        "\n",
        "# Fine-tune\n",
        "trainer.train()\n",
        "\n",
        "# Save model\n",
        "model.save_pretrained(\"/content/t5_finetuned\")\n",
        "tokenizer.save_pretrained(\"/content/t5_finetuned\")\n",
        "print(\"Model fine-tuned and saved!\")\n",
        "\n",
        "# Download the model (optional)\n",
        "!zip -r /content/t5_finetuned.zip /content/t5_finetuned\n",
        "from google.colab import files\n",
        "files.download(\"/content/t5_finetuned.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5-v2Grrydc5"
      },
      "outputs": [],
      "source": [
        "!pip install hf_xet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDkH8LshytEK"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "print(transformers.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfuOUeXJ0g4O"
      },
      "outputs": [],
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# Load the fine-tuned model\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"/content/t5_finetuned\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"/content/t5_finetuned\")\n",
        "\n",
        "# Test transcript (same as provided)\n",
        "test_transcript = \"\"\"Joining in the Q&A after Bob and Mike's comments will be Jacob Thaysen, President of Agilent's Life Sciences and Applied Markets Group; Sam Raha, President of Agilent's Diagnostics and Genomics Group; and Padraig McDonnell, President of Agilent CrossLab Group.\n",
        "You will find the most directly comparable GAAP financial metrics and reconciliations on our website.\n",
        "Core revenue growth excludes the impact of currency and the acquisitions and divestitures completed within the past 12 months.\n",
        "The Agilent team delivered another excellent quarter to close out an outstanding record-setting 2021.\n",
        "At $6.32 billion for fiscal 2021, revenues are almost $1 billion higher than last year.\n",
        "Full year core growth is up 15% on top of growing 1% last year.\n",
        "The strength is broad-based for the three business units, all growing more than 10% core for the year.\n",
        "Our full year operating margin was up 200 basis points.\n",
        "Earnings per share are $4.34 or up 32%.\n",
        "Let's now take a closer look at our strong finish to 2021 and review Q4 results.\n",
        "Our momentum continues as orders increase faster than revenue in Q4.\n",
        "And at the same time, we delivered our fourth straight quarter of double-digit revenue growth.\n",
        "At $1.66 billion, revenues are up 12% on a reported basis.\n",
        "Our core revenues grew 11%, exceeding our expectations.\n",
        "This is on top of 6% core growth last year.\n",
        "Our Q4 operating margin is 26.5%.\n",
        "This is up 160 basis points from last year.\n",
        "EPS is $1.21, up 23% year-over-year.\n",
        "Our earnings growth also exceeded our expectations.\n",
        "We continue to perform extremely well in Pharma, our largest market, growing 21%, driven by our Biopharma business.\n",
        "Total pharma now represents 36% of our overall revenue.\n",
        "This compared to 31% of our revenues just two years ago.\n",
        "The strong growth in our Chemical and Energy business continues as we delivered 11% growth in the quarter.\n",
        "This is on top of growing 3% in Q4 of last year.\n",
        "PMI numbers are positive and we expect that chemical and energy will continue its strong growth trajectory into fiscal 2022.\n",
        "In Diagnostics and Clinical, revenues grew 11% on top of growing 1% last year as testing volume started to recover.\n",
        "On a geographic basis, our results are led by strong performance in the Americas and China.\n",
        "Our business in the Americas grew 15% on top of 5% last year.\n",
        "China grew 8% core on top of strong 13% growth in Q4 of last year.\n",
        "China order growth outpaced revenue growth for the third quarter in a row.\n",
        "Now, looking at a performance by business unit, the Life Sciences and Applied Markets Group generate revenue of $747 million.\n",
        "LSAG is up 11% of both the reported and a core basis.\n",
        "LSAG's growth is broad based and led by strength in liquid chromatography and cell analysis.\n",
        "The Pharma and Chemical Energy markets were particularly strong for new instrument purchases.\n",
        "Our cell analysis business crossed $100 million revenue mark in the quarter for the first time.\n",
        "During the quarter, the LSAG team announced a new high mobility LC/Q-TOF and enhancements to our VWorks automation software suite.\n",
        "These new well received offerings are used to improved analysis of proteins and peptides to speed development of new protein-based therapeutics.\n",
        "The Agilent CrossLab Group posted revenue of $572 million.\n",
        "This is up reported 10% and 9% core.\n",
        "Growth is broad based, driven by strength in service contracts and on-demand services as well as our chemistries and supplies.\n",
        "Our focus on increasing connect rates continues to pay off for us.\n",
        "The strong expansion of our installed base in 2021 and increasing connect rates bodes well continued to strengthen our ACG business moving forward.\n",
        "Our ability to drive growth and leverage our scale produce operating margins of roughly 30%, not more than 200 basis points from the prior year.\n",
        "The Diagnostics and Genomics Group delivered revenue of $341 million, up 16% reported and up 13% core.\n",
        "Our NASD oligo business led the way with robust double-digit growth in the quarter and achieved full year revenues exceeding $225 million.\n",
        "We expect another year of strong double-digit growth as the team continues to do a great job of increasing throughput with existing capacity.\n",
        "The expansion of our Train B oligo manufacturing facility in Frederick, Colorado is proceeding as planned.\n",
        "We expect this additional capacity to come online by the end of calendar year 2022.\n",
        "Moving on from our other business group updates, there are several other significant developments for Agilent this quarter.\n",
        "We announced our commitment to achieving net zero greenhouse gas emissions by 2050.\n",
        "We believe our approach delivers the same rigorous sustainability that'd be applied to everything else we do.\n",
        "We also believe these actions are not only the right thing to do, but fundamental to achieving long-term success.\n",
        "Our sustainable leadership continues to be primarily recognized as well.\n",
        "You may have seen that Investor's Business Daily recently named Agilent to its Top 100 ESG Companies list.\n",
        "We're also a company where diversity and inclusion represent a company priority and is a core element of our culture.\n",
        "During the quarter, we achieved recognition by Forbes as one of the World's Best Employers and as a Best Workplace for Women.\n",
        "While the Agilent team has a strong track record of delivering above-market growth and leading customer satisfaction, we're always looking to do more.\n",
        "To further accelerate growth and strengthen our focus on customers, we are implementing a new One Agilent commercialization, combining for the first time all customer-facing activities under one leader.\n",
        "The new organization brings together and strengthens our sales, marketing, digital channel and services team.\n",
        "The new enterprise level commercialization is led by Padraig McDonnell.\n",
        "Padraig will continue to lead the Agilent CrossLab Group as Business Group President as well as serves Agilent's first ever Chief Commercial Officer.\n",
        "The way I'd like to characterize this move is to say we are doubling down on the success we've achieved with ACG, applying a holistic customer-focused approach to all aspects of our business.\n",
        "We're also moving the chemistries and supplies division to LSAG.\n",
        "This close organizational alignment between instrument and chemistries development will further accelerate our progress on instrument connect rates for chemistries and consumables.\n",
        "We believe that structure of follow strategy and that this new organizational structure will further enhance our customer focus and the execution of our growth strategies.\n",
        "Looking ahead to the coming year, we are in a strong position to continue to deliver on our build and buy growth strategy.\n",
        "Agilent's business remains strong.\n",
        "We enter the new year with a robust backlog and have multiple growth drivers, coupled with the proven execution excellence of the Agilent team.\n",
        "A year ago to our Agilent Investor Day, we raised our long-term annual growth outlook to the 5% to 7% range, while reaffirming our commitment to annual operating margin improvement and double-digit earnings per share growth.\n",
        "We are now one year in and well on our way to achieving these long-term goals.\n",
        "Bob will provide more details, but for fiscal 2022, our initial full year guide calls for a core growth in the range of 5.5% to 7%.\n",
        "We expect to continue our top line growth as we launch market-leading products and services, invest in fast-growing businesses and deliver outstanding customer service.\n",
        "My confidence in the unstoppable One Agilent team and our ability to execute and deliver remains firmly intact.\n",
        "This is our formula for delivering solid financial results, outstanding shareholder returns and continued strong growth.\n",
        "We are very pleased with our performance in 2021 but not satisfied.\n",
        "As I tell the Agilent team, the best is yet to come for our customers, our team and our shareholders.\n",
        "I will now hand the call off to Bob.\n",
        "In my remarks today, I'll provide some additional details on revenue and take you through the income statement and some other key financial metrics.\n",
        "I'll then finish up with our initial outlook for the upcoming year and for the first quarter.\n",
        "As Mike mentioned, we had very strong results in the fourth quarter.\n",
        "Revenue was $1.66 billion, reflecting reported growth of 12%.\n",
        "Core revenue growth at 11% was a point above our top end guidance range.\n",
        "Currency accounted for 0.8% of growth, while M&A contributed half a point of growth during Q4.\n",
        "And as expected, COVID-19-related revenues were roughly flat sequentially and resulted in just over a point headwind to the quarterly revenue growth.\n",
        "Late in the quarter, we did see transit times that were in certain cases greater than anticipated, resulting in some revenues being deferred into Q1.\n",
        "Our results were driven by a continuation of outstanding momentum in Pharma and in Biopharma in particular, while Chemical and Energy and Diagnostics and clinical also delivered strong results for us.\n",
        "Our largest market, Pharma, grew 21% during the quarter against a tough compare of 12% last year.\n",
        "The Small Molecule segment delivered mid-teens growth, while Large Molecule grew 30%.\n",
        "Pharma was a standout all year, growing 24% for the full year after growing 6% in 2020.\n",
        "And in FY '22, we expect our Pharma business to grow in the high-single digits.\n",
        "Chemical and Energy continue to show strength growing 11% with instrument growth in the mid-teens during the quarter.\n",
        "This impressive performance was against a 3% increase last year.\n",
        "The C&E business grew 12% for the year after declining 3% in 2020.\n",
        "Growth was driven by continued momentum in chemicals and engineered materials and we expect our C&E business to continue to grow solidly next year in the high-single digits.\n",
        "Diagnostics and Clinical grew 11% with all three groups growing nicely during the quarter.\n",
        "While the largest dollar contributor to this market is DGG, driven by our pathology-related businesses, the LSAG business continues to penetrate the clinical market and drive growth with strong performances by Cell Analysis and Mass Spec.\n",
        "We saw mid-teens growth in the Americas and strong growth in China, albeit off a small base.\n",
        "For the year, the Diagnostics and Clinical business grew 15% for the year after declining slightly by 1% in 2020.\n",
        "And we expect to continue to grow in the mid to high-single digits in 2022.\n",
        "Academia and Government, which can be lumpy and represents less than 10% of our business, was up 1% in Q4 versus a flat growth last year.\n",
        "Most research labs continue to remain open globally and increase capacity to pre-pandemic levels.\n",
        "China came in at low-single digits, while the Americas and Europe were roughly flat.\n",
        "For the year, we grew 7% after declining 4% last year.\n",
        "We expect this market will continue to improve slightly in fiscal year 2022 and expect growth of low to mid-single digits.\n",
        "Food was flat during the quarter against a very tough 16% compare.\n",
        "Europe and the Americas grew while China declined.\n",
        "For the year, food grew 13% after growing 7% in 2020.\n",
        "Looking forward, we expect food to return to historical growth rates in the low-single digits.\n",
        "And rounding out the markets, Environmental and Forensics declined 2% in the fourth quarter off of 5% decline last year as growth in Environmental was overshadowed by a decline in Forensics.\n",
        "For the year, we grew 5%, off a 2% decline in 2020.\n",
        "And looking forward, like Food, we expect Environmental and Forensics to grow in the low-single digits in the coming year.\n",
        "For Agilent overall, on a geographic basis, all regions again grew in Q4, led by Americas at 15% China grew 8% in Europe grew 4%.\n",
        "And for the year, Americas led the way with 21% growth, followed by China at 13% and Europe at 12%.\n",
        "Now let's turn to the rest of the P&L.\n",
        "Fourth quarter gross margin was 55.9%, up 90 basis points from a year ago.\n",
        "Gross margin performance, along with continued operating expense leverage, resulted in an operating margin for the fourth quarter of 26.5%, improving 160 basis points over last year.\n",
        "Putting it all together, we delivered earnings per share of $1.21, up 23% versus last year.\n",
        "And during the quarter, we benefited from some additional tax savings, resulting in a quarterly tax rate of 13% and our full year tax rate was 14.25%.\n",
        "Our share count was 305 million shares as expected.\n",
        "And for the year, earnings per share came in at $4.34, an increase of 32% from 2020.\n",
        "We continued our strong cash flow generation, resulting in $441 million for the quarter, an increase of 17% versus last year.\n",
        "For all of 2021, we generated almost $1.5 billion in operating cash and invested $188 million in capital expenditures.\n",
        "During the quarter, we returned $195 million to our shareholders paying out $59 million in dividends and repurchasing roughly 830,000 shares for $136 million.\n",
        "And for the year, we returned over $1 billion to shareholders in the forms of dividends and share repurchases.\n",
        "And we ended the year with $1.5 billion in cash and $2.7 billion in outstanding debt and a net leverage ratio of 0.7 times.\n",
        "All in all, a great end to an outstanding year.\n",
        "Now let's move on to the outlook for fiscal 2022.\n",
        "While we are still dealing with the pandemic and we have the additional challenges around logistics and inflationary pressures, we enter the year with strong backlog and momentum.\n",
        "For the full year, we're expecting revenue to range between $6.65 billion and $6.73 billion, representing reported growth of 5% to 6.5% and core growth of 5.5% to 7%, consistent with our long-range goals.\n",
        "And this incorporates absorbing roughly 0.5% headwind associated with COVID-related revenues with the majority of that impact coming in Q1.\n",
        "We're expecting all three of our businesses to grow, led by DGG.\n",
        "We expect DGG to grow high-single digits with the continued contribution of NASD in cancer diagnostics.\n",
        "We expect ACG to grow at high-single digits with both services in our chemistries and supplies businesses growing comparably while LSAG is expected to grow in mid-single digits.\n",
        "We expect operating margin expansion of 60 to 80 basis points for the year as we absorb the build-out costs of Train B at our Frederick, Colorado NASD site.\n",
        "And in helping you build out your models, we're planning for a tax rate of 14.25%, consistent with current tax policies and $305 million fully diluted shares outstanding.\n",
        "All this translates to a fiscal 2022 non-GAAP earnings per share expected to be between $4.76 to $4.86 per share, resulting in double-digit growth.\n",
        "And finally, we expect operating cash flow of approximately $1.4 billion to $1.5 billion and capital expenditures of $300 million.\n",
        "This capital investment represents an increase over 2021 as we continue our focus on growth, bringing our NASD Train B expansion online and expanding consumables manufacturing capacity for our Cell Analysis and Genomics businesses.\n",
        "We have also announced raising our dividend by 8%, continuing an important streak of dividend increases and providing another source of value to our shareholders.\n",
        "Now let's move on to our first quarter guidance.\n",
        "But before I get into the specifics, some additional context.\n",
        "Lunar New Year is February 1 this year, a shift from last year when it was in mid-February.\n",
        "As a result, we expect some Q1 revenue to shift to the second quarter of this year as customers shut down ahead of the holiday.\n",
        "In addition, as I mentioned, we do expect to see the largest impact of COVID-related revenue headwinds in the first quarter.\n",
        "We estimate these two factors will impact our base business growth by 2 to 3 points and roughly equal in impact.\n",
        "For Q1, we are expecting revenue to range from $1.64 billion to $1.66 billion, representing reported and core growth of 5.9% to 7.2%.\n",
        "Adjusting for the timing of Lunar New Year and COVID-related headwinds, core growth would be roughly 8% to 10% in the quarter.\n",
        "First quarter 2022 non-GAAP earnings are expected to be in the range of $1.16 to $1.18.\n",
        "In conjunction with the new One Agilent commercial organization Mike talked about, we will be reporting under the new structure starting in Q1.\n",
        "In addition, we'll be providing a recast of certain LSAG and ACG historical financials to account for the segment changes after the filing of our Annual Report on Form 10-K in December.\n",
        "I am extremely proud of what the Agilent team achieved in 2021 and look forward to another strong performance in 2022.\n",
        "With that for me, back to you for Q&A.\n",
        "Bethany, if you could please provide instructions for the Q&A now.\n",
        "\"\"\"\n",
        "# Post-process to remove redundancy and shorten\n",
        "def refine_summary(summary):\n",
        "    sentences = summary.split(\". \")\n",
        "    seen = set()\n",
        "    refined_sentences = []\n",
        "    for sentence in sentences:\n",
        "        if sentence and sentence not in seen:\n",
        "            seen.add(sentence)\n",
        "            refined_sentences.append(sentence)\n",
        "    refined_summary = \". \".join(refined_sentences)\n",
        "    if len(refined_summary.split()) > 75:  # Limit to ~75 words\n",
        "        refined_summary = \" \".join(refined_summary.split()[:75])\n",
        "    return refined_summary.strip() + (\". \" if not refined_summary.endswith(\".\") else \"\")\n",
        "\n",
        "\n",
        "\n",
        "# Split the transcript into chunks of ~400 words\n",
        "def split_text(text, max_words=400):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    word_count = 0\n",
        "    for word in words:\n",
        "        current_chunk.append(word)\n",
        "        word_count += 1\n",
        "        if word_count >= max_words:\n",
        "            chunks.append(\" \".join(current_chunk))\n",
        "            current_chunk = []\n",
        "            word_count = 0\n",
        "    if current_chunk:\n",
        "        chunks.append(\" \".join(current_chunk))\n",
        "    return chunks\n",
        "\n",
        "# Split the transcript\n",
        "chunks = split_text(test_transcript)\n",
        "\n",
        "# Summarize each chunk\n",
        "chunk_summaries = []\n",
        "for chunk in chunks:\n",
        "    inputs = tokenizer(\"summarize: \" + chunk, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    summary_ids = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_length=150,\n",
        "        min_length=30,\n",
        "        num_beams=4,\n",
        "        no_repeat_ngram_size=2,  # Prevent repetition\n",
        "        early_stopping=False\n",
        "    )\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    if summary.strip():  # Only add non-empty summaries\n",
        "        chunk_summaries.append(summary)\n",
        "\n",
        "# Combine chunk summaries\n",
        "final_summary = \" \".join(chunk_summaries)\n",
        "refined_summary = refine_summary(final_summary)\n",
        "print(f\"Refined Summary: {refined_summary}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUSaAwkQx749"
      },
      "outputs": [],
      "source": [
        "!pip install pinecone sentence-transformers pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKThJPINys4d"
      },
      "outputs": [],
      "source": [
        "# Uninstall pinecone-client\n",
        "!pip uninstall -y pinecone-client\n",
        "\n",
        "# Ensure pinecone is installed\n",
        "!pip install pinecone --upgrade\n",
        "\n",
        "# Verify the installed package\n",
        "!pip show pinecone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IReNUyWfxMAL"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Import libraries\n",
        "import pinecone\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize Pinecone client\n",
        "client = pinecone.Pinecone(api_key=\"pcsk_3z4iTz_BoTpE3CrVJVTUvF37hWHeN5Eo6XnosKTjidbKsvb9FotdUETgUnDNpXqHkCFVN9\")\n",
        "\n",
        "# Define index name\n",
        "index_name = \"financial-docs\"\n",
        "\n",
        "# Create index if it doesn't exist\n",
        "if index_name not in client.list_indexes().names():\n",
        "    client.create_index(\n",
        "        name=index_name,\n",
        "        dimension=384,\n",
        "        metric=\"cosine\",\n",
        "        spec=pinecone.ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
        "    )\n",
        "\n",
        "# Connect to the index\n",
        "index = client.Index(index_name)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/financial_data.csv\")\n",
        "\n",
        "# Load embedding model\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Generate embeddings\n",
        "embeddings = embedder.encode(df[\"transcript\"].tolist(), show_progress_bar=True)\n",
        "\n",
        "# Prepare vectors with truncated metadata\n",
        "ids = [str(i) for i in range(len(df))]\n",
        "vectors = [(ids[i], embeddings[i].tolist(), {\"text\": df[\"transcript\"][i][:500]}) for i in range(len(df))]  # Limit to 500 characters\n",
        "\n",
        "# Batch upsert\n",
        "batch_size = 50  # Can increase batch size since metadata is smaller\n",
        "for i in range(0, len(vectors), batch_size):\n",
        "    batch = vectors[i:i + batch_size]\n",
        "    index.upsert(vectors=batch)\n",
        "    print(f\"Uploaded batch {i // batch_size + 1} of {len(vectors) // batch_size + 1}\")\n",
        "\n",
        "\n",
        "print(\"Documents stored in Pinecone!\")\n",
        "# Save transcript mapping\n",
        "df[\"pinecone_id\"] = ids\n",
        "df[[\"pinecone_id\", \"transcript\"]].to_csv(\"/content/transcript_mapping.csv\", index=False)\n",
        "print(\"Transcript mapping saved to /content/transcript_mapping.csv\")\n",
        "\n",
        "# Save to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp /content/transcript_mapping.csv /content/drive/MyDrive/transcript_mapping.csv\n",
        "print(\"Transcript mapping copied to Google Drive!\")\n",
        "\n",
        "# Test Pinecone retrieval\n",
        "queries = [\n",
        "    \"What is the revenue growth for Pharma?\",\n",
        "    \"Pharma grew 21% in Q4 2021, driven by Biopharma.\",\n",
        "    \"How did the pharmaceutical sector perform?\"\n",
        "]\n",
        "\n",
        "for query in queries:\n",
        "    query_embedding = embedder.encode([query])[0].tolist()\n",
        "    results = index.query(vector=query_embedding, top_k=3, include_metadata=True)\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "    for match in results['matches']:\n",
        "        print(f\"Score: {match['score']}, ID: {match['id']}, Text: {match['metadata']['text'][:100]}...\")\n",
        "\n",
        "# Step 5: Combined Search and Summarization System\n",
        "\n",
        "# Load the fine-tuned T5 model (after re-uploading or retraining)\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"/content/t5_finetuned\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"/content/t5_finetuned\")\n",
        "\n",
        "# Load transcript mapping\n",
        "mapping = pd.read_csv(\"/content/transcript_mapping.csv\")\n",
        "\n",
        "# Search and summarize\n",
        "query = \"What is the revenue growth for Pharma?\"\n",
        "query_embedding = embedder.encode([query])[0].tolist()\n",
        "results = index.query(vector=query_embedding, top_k=1, include_metadata=True)\n",
        "\n",
        "if results['matches']:\n",
        "    top_id = results['matches'][0]['id']\n",
        "    top_transcript = mapping[mapping[\"pinecone_id\"] == top_id][\"transcript\"].values[0]\n",
        "    inputs = tokenizer(\"summarize: \" + top_transcript, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    summary_ids = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_length=100,\n",
        "        min_length=20,\n",
        "        num_beams=6,\n",
        "        no_repeat_ngram_size=3,\n",
        "        length_penalty=1.0,\n",
        "        early_stopping=False\n",
        "    )\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "    print(f\"Summary: {summary}\")\n",
        "else:\n",
        "    print(\"No matching transcripts found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oq7vEs-10RcU"
      },
      "outputs": [],
      "source": [
        "query = \"What is the revenue growth for Pharma?\"\n",
        "query_embedding = embedder.encode([query])[0].tolist()\n",
        "results = index.query(vector=query_embedding, top_k=3, include_metadata=True)\n",
        "for match in results['matches']:\n",
        "    print(f\"Score: {match['score']}, Text: {match['metadata'].get('text', 'No metadata')[:100]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "larr6uXA0qd4"
      },
      "outputs": [],
      "source": [
        "!zip -r /content/t5_finetuned.zip /content/t5_finetuned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "sL3Ln6DkNjki",
        "outputId": "e8213b95-d895-4e07-d739-3c77104ce0fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upload t5_finetuned.zip:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f9c4bb0d-8760-4603-97ee-7299bd624b3a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f9c4bb0d-8760-4603-97ee-7299bd624b3a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0342bd34aa8e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Upload t5_finetuned.zip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Upload t5_finetuned.zip:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unzip /content/t5_finetuned.zip -d /content'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"t5_finetuned directory restored!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Step 1: Upload necessary files\n",
        "from google.colab import files\n",
        "\n",
        "# Upload t5_finetuned.zip\n",
        "print(\"Upload t5_finetuned.zip:\")\n",
        "uploaded = files.upload()\n",
        "!unzip /content/t5_finetuned.zip -d /content\n",
        "print(\"t5_finetuned directory restored!\")\n",
        "\n",
        "# Upload financial_data.csv and transcript_mapping.csv\n",
        "print(\"Upload financial_data.csv and transcript_mapping.csv:\")\n",
        "uploaded = files.upload()\n",
        "print(\"Files uploaded!\")\n",
        "\n",
        "# Step 2: Install dependencies\n",
        "!pip install pinecone sentence-transformers transformers pandas gradio\n",
        "print(\"Dependencies installed!\")\n",
        "\n",
        "# Step 3: Rebuild or reconnect to the Pinecone index\n",
        "import pinecone\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize Pinecone client\n",
        "client = pinecone.Pinecone(api_key=\"pcsk_3z4iTz_BoTpE3CrVJVTUvF37hWHeN5Eo6XnosKTjidbKsvb9FotdUETgUnDNpXqHkCFVN9\")\n",
        "\n",
        "# Define index name\n",
        "index_name = \"financial-docs\"\n",
        "\n",
        "# Check if the index exists; if not, create it\n",
        "if index_name not in client.list_indexes().names():\n",
        "    print(f\"Index {index_name} does not exist. Creating it...\")\n",
        "    client.create_index(\n",
        "        name=index_name,\n",
        "        dimension=384,\n",
        "        metric=\"cosine\",\n",
        "        spec=pinecone.ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
        "    )\n",
        "\n",
        "    # Connect to the index\n",
        "    index = client.Index(index_name)\n",
        "\n",
        "    # Load dataset\n",
        "    df = pd.read_csv(\"/content/financial_data.csv\")\n",
        "\n",
        "    # Load embedding model\n",
        "    embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "    # Generate embeddings\n",
        "    embeddings = embedder.encode(df[\"transcript\"].tolist(), show_progress_bar=True)\n",
        "\n",
        "    # Prepare vectors with truncated metadata\n",
        "    ids = [str(i) for i in range(len(df))]\n",
        "    vectors = [(ids[i], embeddings[i].tolist(), {\"text\": df[\"transcript\"][i][:500]}) for i in range(len(df))]\n",
        "\n",
        "    # Batch upsert\n",
        "    batch_size = 50\n",
        "    for i in range(0, len(vectors), batch_size):\n",
        "        batch = vectors[i:i + batch_size]\n",
        "        index.upsert(vectors=batch)\n",
        "        print(f\"Uploaded batch {i // batch_size + 1} of {len(vectors) // batch_size + 1}\")\n",
        "\n",
        "    print(\"Documents stored in Pinecone!\")\n",
        "else:\n",
        "    print(f\"Index {index_name} already exists. Connecting to it...\")\n",
        "    index = client.Index(index_name)\n",
        "\n",
        "# Step 4: Recreate the Gradio UI\n",
        "import gradio as gr\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# Load the embedding model\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Connect to the Pinecone index (already connected, but ensuring it's available)\n",
        "index = client.Index(\"financial-docs\")\n",
        "\n",
        "# Load the fine-tuned T5 model\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"/content/t5_finetuned\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"/content/t5_finetuned\")\n",
        "\n",
        "# Load transcript mapping\n",
        "mapping = pd.read_csv(\"/content/transcript_mapping.csv\")\n",
        "\n",
        "# Define the search and summarize function for the UI\n",
        "def search_and_summarize(query):\n",
        "    # Search Pinecone\n",
        "    query_embedding = embedder.encode([query])[0].tolist()\n",
        "    results = index.query(vector=query_embedding, top_k=1, include_metadata=True)\n",
        "\n",
        "    if not results['matches']:\n",
        "        return \"No matching transcripts found.\", \"\"\n",
        "\n",
        "    # Retrieve the top result\n",
        "    top_match = results['matches'][0]\n",
        "    top_id = top_match['id']\n",
        "    score = top_match['score']\n",
        "    truncated_text = top_match['metadata']['text']\n",
        "\n",
        "    # Get the full transcript\n",
        "    top_transcript = mapping[mapping[\"pinecone_id\"] == top_id][\"transcript\"].values[0]\n",
        "\n",
        "    # Generate summary\n",
        "    inputs = tokenizer(\"summarize: \" + top_transcript, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    summary_ids = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_length=100,\n",
        "        min_length=20,\n",
        "        num_beams=6,\n",
        "        no_repeat_ngram_size=3,\n",
        "        length_penalty=1.0,\n",
        "        early_stopping=False\n",
        "    )\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    # Format the output\n",
        "    search_result = f\"**Top Matching Transcript (ID: {top_id}, Score: {score:.2f})**\\n{truncated_text}...\"\n",
        "    return search_result, summary\n",
        "\n",
        "# Build the Gradio UI\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Financial Report Summarizer\")\n",
        "    gr.Markdown(\"Enter a query to search financial transcripts and get a summary.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        query_input = gr.Textbox(label=\"Query\", placeholder=\"e.g., What is the revenue growth for Pharma?\")\n",
        "        submit_button = gr.Button(\"Search and Summarize\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            search_output = gr.Textbox(label=\"Search Result (Top Matching Transcript)\")\n",
        "        with gr.Column():\n",
        "            summary_output = gr.Textbox(label=\"Summary\")\n",
        "\n",
        "    # Connect the button to the function\n",
        "    submit_button.click(\n",
        "        fn=search_and_summarize,\n",
        "        inputs=query_input,\n",
        "        outputs=[search_output, summary_output]\n",
        "    )\n",
        "\n",
        "# Launch the UI\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaD6IQSSO-s2"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "def create_zip(file_path, zip_file_path):\n",
        "    \"\"\"\n",
        "    Creates a zip file containing the file specified by file_path.\n",
        "\n",
        "    Args:\n",
        "        file_path: The path to the file to be zipped.\n",
        "        zip_file_path: The path to the output zip file.\n",
        "    \"\"\"\n",
        "    with zipfile.ZipFile(zip_file_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        zipf.write(file_path)\n",
        "file_path = 't5_finetuned'\n",
        "zip_file_path = 't5_finetuned_weights.zip'\n",
        "create_zip(file_path, zip_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cx_9ZAn0QAoR"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "def zip_folder(folder_path, output_path):\n",
        "    \"\"\"\n",
        "    Zips a folder and its contents.\n",
        "\n",
        "    Args:\n",
        "        folder_path (str): The path to the folder to be zipped.\n",
        "        output_path (str): The path and name of the output zip file (without extension).\n",
        "    \"\"\"\n",
        "    if not os.path.exists(folder_path):\n",
        "        raise FileNotFoundError(f\"Folder not found: {folder_path}\")\n",
        "\n",
        "    shutil.make_archive(output_path, 'zip', folder_path)\n",
        "    print(f\"Folder '{folder_path}' zipped to '{output_path}.zip'\")\n",
        "\n",
        "# Example usage\n",
        "folder_to_zip = 't5_finetuned' # Replace with your folder path\n",
        "output_zip_name = 't5_finetuned_weights.zip' # Replace with your desired output name\n",
        "\n",
        "# Create a dummy folder and file for testing\n",
        "os.makedirs(folder_to_zip, exist_ok=True)\n",
        "with open(os.path.join(folder_to_zip, 'test.txt'), 'w') as f:\n",
        "    f.write('This is a test file.')\n",
        "\n",
        "zip_folder(folder_to_zip, output_zip_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FswYHMLRhyv",
        "outputId": "caa39291-d99b-481d-bd37-1fb7a6eaff9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 2.1G May 20 01:59 t5_finetuned.zip\n"
          ]
        }
      ],
      "source": [
        "!ls -lh t5_finetuned.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8pf5EGkSNCr"
      },
      "outputs": [],
      "source": [
        "print(\"Contents of checkpoint-970:\")\n",
        "!ls -lh /content/t5_finetuned/checkpoint-970\n",
        "print(\"\\nContents of checkpoint-1940:\")\n",
        "!ls -lh /content/t5_finetuned/checkpoint-1940\n",
        "print(\"\\nContents of checkpoint-2910:\")\n",
        "!ls -lh /content/t5_finetuned/checkpoint-2910"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIdCI_oiSatN",
        "outputId": "dd2377cb-ee0f-4a30-9954-e7af73878ad6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True size of t5_finetuned directory (including subdirectories):\n",
            "2.3G\t/content/t5_finetuned\n",
            "rm: cannot remove '/content/t5_finetuned/test.txt': No such file or directory\n",
            "\n",
            "Contents of t5_finetuned after cleanup:\n",
            "total 232M\n",
            "-rw-r--r-- 1 root root 2.6K May 20 01:56 added_tokens.json\n",
            "-rw-r--r-- 1 root root 1.5K May 20 01:56 config.json\n",
            "-rw-r--r-- 1 root root  142 May 20 01:56 generation_config.json\n",
            "-rw-r--r-- 1 root root 231M May 20 01:56 model.safetensors\n",
            "-rw-r--r-- 1 root root 2.5K May 20 01:56 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root 774K May 20 01:56 spiece.model\n",
            "-rw-r--r-- 1 root root  21K May 20 01:56 tokenizer_config.json\n",
            "232M\t/content/t5_finetuned\n",
            "  adding: content/t5_finetuned/ (stored 0%)\n",
            "  adding: content/t5_finetuned/model.safetensors"
          ]
        }
      ],
      "source": [
        "# Check the true size of the directory\n",
        "print(\"True size of t5_finetuned directory (including subdirectories):\")\n",
        "!du -sh /content/t5_finetuned\n",
        "\n",
        "# Remove unnecessary files\n",
        "!rm -rf /content/t5_finetuned/checkpoint-*  # Remove checkpoints\n",
        "!rm -rf /content/t5_finetuned/runs          # Remove training logs (if any)\n",
        "!rm /content/t5_finetuned/test.txt          # Remove test.txt\n",
        "\n",
        "# Verify the cleaned directory\n",
        "print(\"\\nContents of t5_finetuned after cleanup:\")\n",
        "!ls -lh /content/t5_finetuned\n",
        "!du -sh /content/t5_finetuned\n",
        "\n",
        "# Recompress the cleaned directory\n",
        "!zip -9 -r /content/t5_finetuned_cleaned.zip /content/t5_finetuned\n",
        "print(\"t5_finetuned directory recompressed into t5_finetuned_cleaned.zip!\")\n",
        "\n",
        "# Verify the new ZIP file size\n",
        "!ls -lh /content/t5_finetuned_cleaned.zip\n",
        "\n",
        "# Save to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp /content/t5_finetuned_cleaned.zip /content/drive/MyDrive/t5_finetuned_cleaned.zip\n",
        "print(\"t5_finetuned_cleaned.zip copied to Google Drive!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "002a2d501d174a6f82bb6c12932f27cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "020a95734a674ecfbe47de1335328ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bc53d7259764f7abf914cebb67f4080",
            "placeholder": "​",
            "style": "IPY_MODEL_7d1982fa1e96406e9d7ea7f1be67bb73",
            "value": " 2.32k/2.32k [00:00&lt;00:00, 242kB/s]"
          }
        },
        "021b14a88fb5447c932533c03b0b3d3f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03562f72b92e426b9c839e41e16724a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "038603815d674f77ac694a9bd462d5a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08632020ac154eeea23e170454e0b959": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_021b14a88fb5447c932533c03b0b3d3f",
            "placeholder": "​",
            "style": "IPY_MODEL_66b417870da6439ba2fafcc3c66551a9",
            "value": "Map: 100%"
          }
        },
        "09793013b5474f679e781f7a7b574c79": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b8202da2ff342e18a57951572e0a39e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d84f667aca6c4179a930fb24b00269e3",
            "placeholder": "​",
            "style": "IPY_MODEL_bea016d468ff4c9da7303715fc9588f1",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "12032e37d36242808f6960223de2510e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "156b8c7a82e74fe0b4368e761df79982": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1611b5cb7d52425b9bc6beb0969adf2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17f054ad311d47e3acd0d7502466ede5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b2ab8e1ec8748158c44f667ec561a13",
              "IPY_MODEL_ed63cadc2bd24f2a830710a28b1eb22c",
              "IPY_MODEL_963301adba1e435491fd35994f65654a"
            ],
            "layout": "IPY_MODEL_d1a54dd2fd074a74b1c8710db2db3b69"
          }
        },
        "1af5466dc6994369922e64e8dff9f2c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ca6a08f443d4539b56c7f341f040695": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f144892695c488e938599a88cb83fb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_221b34f6645f4c008cab14c512f6f2df",
            "placeholder": "​",
            "style": "IPY_MODEL_03562f72b92e426b9c839e41e16724a1",
            "value": " 2425/2425 [00:36&lt;00:00, 65.82 examples/s]"
          }
        },
        "221b34f6645f4c008cab14c512f6f2df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b2ab8e1ec8748158c44f667ec561a13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8f05ef6ab454921ba0fb3f155ad2465",
            "placeholder": "​",
            "style": "IPY_MODEL_f14a8378ab87457086fe2f4a7861a110",
            "value": "generation_config.json: 100%"
          }
        },
        "2f5a653a51644a1cbb6c1f93a447e577": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "308f57eb67ff485789982a5b8e5946de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "375b00ed46984e7fb26751a8b718c0db": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bad5d0c59804481bfd7cf1b29f3129a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e42d7bf9c6f414285abe2fe38ba8cfc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53e13e7815d94c34b579e8568e6375c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f83002e813f94a16b58e49d2e0d33eb7",
            "max": 242043056,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e473108aa2fa4bbc8a7b7c1452e0a299",
            "value": 242043056
          }
        },
        "5672569e3eff4e708e493045eda1949b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dbc06cefa88e4a968c2b0ec9a9841cae",
              "IPY_MODEL_78b45f2094034f20876e2d771240a500",
              "IPY_MODEL_a91d0926579945a6897ab6fd1da0e290"
            ],
            "layout": "IPY_MODEL_09793013b5474f679e781f7a7b574c79"
          }
        },
        "5939590b59134f569060788988cfcee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d5ff926ae3a48cfb07dba6827c37507",
              "IPY_MODEL_68b2fb4065464eabb7d7e07788ac7380",
              "IPY_MODEL_694a0256fe694f76b972d6459e04b89b"
            ],
            "layout": "IPY_MODEL_3e42d7bf9c6f414285abe2fe38ba8cfc"
          }
        },
        "5bc53d7259764f7abf914cebb67f4080": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cbdd6142aed47079f8dd02d9dc00d23": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ccc70176ee741fbaf68d09411b86bef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65560493d0894132b745be466c6a2448": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66b417870da6439ba2fafcc3c66551a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68b2fb4065464eabb7d7e07788ac7380": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65560493d0894132b745be466c6a2448",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6fb430591ae44dcd948849f1f13111a6",
            "value": 791656
          }
        },
        "694a0256fe694f76b972d6459e04b89b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e150f0f362949cf8be29d44d10f7fc0",
            "placeholder": "​",
            "style": "IPY_MODEL_2f5a653a51644a1cbb6c1f93a447e577",
            "value": " 792k/792k [00:00&lt;00:00, 27.6MB/s]"
          }
        },
        "6fb18fb7c3a34d7383327144ddeeaaec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fb430591ae44dcd948849f1f13111a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78b45f2094034f20876e2d771240a500": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_950c4769e85243749b0c50cfae371eba",
            "max": 1206,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f0351c77b994a75a40fd0e704939ed7",
            "value": 1206
          }
        },
        "7a852405cb9a4798a75cabf43aa1dab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_002a2d501d174a6f82bb6c12932f27cf",
            "placeholder": "​",
            "style": "IPY_MODEL_5ccc70176ee741fbaf68d09411b86bef",
            "value": "Batches: 100%"
          }
        },
        "7d1982fa1e96406e9d7ea7f1be67bb73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d5ff926ae3a48cfb07dba6827c37507": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fb18fb7c3a34d7383327144ddeeaaec",
            "placeholder": "​",
            "style": "IPY_MODEL_8b8176b0bd354f3c95909cbced7a828c",
            "value": "spiece.model: 100%"
          }
        },
        "7e02f25143c54537bd29cb58533b5d99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8927e90352bd4ad38340f87935c4cf7f",
              "IPY_MODEL_bc161ecdfc814da38eb75dadc8566230",
              "IPY_MODEL_a289b33a66dc4081a4e4b2b17dda98e6"
            ],
            "layout": "IPY_MODEL_80291b0e9eb64287a4b97679126c2471"
          }
        },
        "7e150f0f362949cf8be29d44d10f7fc0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80291b0e9eb64287a4b97679126c2471": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8927e90352bd4ad38340f87935c4cf7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd073a9d053e43a0a88c337e3927a232",
            "placeholder": "​",
            "style": "IPY_MODEL_91b8e9dc648341a9b14da39d33942a27",
            "value": "tokenizer.json: 100%"
          }
        },
        "8b8176b0bd354f3c95909cbced7a828c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f75f7643252428ba2f81f2f405d453c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90588558ea724f4590939d4e3722bc65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91b8e9dc648341a9b14da39d33942a27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9276d0baa80b48e19a775b1467044e88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "950c4769e85243749b0c50cfae371eba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "963301adba1e435491fd35994f65654a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_156b8c7a82e74fe0b4368e761df79982",
            "placeholder": "​",
            "style": "IPY_MODEL_c459955c82774374bd6f924dccfb044e",
            "value": " 147/147 [00:00&lt;00:00, 9.41kB/s]"
          }
        },
        "9b25a1bd9ae74451ae8951050f39cb85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_beac7e6851de425d8f57b01118bd90e5",
            "max": 2324,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7967e664c6d4fc6ae879a7d9d93e2b0",
            "value": 2324
          }
        },
        "9f0351c77b994a75a40fd0e704939ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9fd4862163c843989eaa8b38e6042c3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3211feee5e04bc2af90fcc76a5ca338",
            "max": 2425,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b369329812b145fbad34b0e3a00720cd",
            "value": 2425
          }
        },
        "a289b33a66dc4081a4e4b2b17dda98e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_038603815d674f77ac694a9bd462d5a1",
            "placeholder": "​",
            "style": "IPY_MODEL_1af5466dc6994369922e64e8dff9f2c9",
            "value": " 1.39M/1.39M [00:00&lt;00:00, 6.44MB/s]"
          }
        },
        "a3211feee5e04bc2af90fcc76a5ca338": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a885f8682d3c4309ba7c27e9b466eded": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a91d0926579945a6897ab6fd1da0e290": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7eec62138654512b041ab2ef917deaf",
            "placeholder": "​",
            "style": "IPY_MODEL_fd45b722101340768dac9f7106b301b9",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 84.1kB/s]"
          }
        },
        "aaa5140041a9414a9c1fe1ce91ba298a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0771b9a98bb408bb30f54066160c1f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b216605498c44c1880248d49bcefb89d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b8202da2ff342e18a57951572e0a39e",
              "IPY_MODEL_9b25a1bd9ae74451ae8951050f39cb85",
              "IPY_MODEL_020a95734a674ecfbe47de1335328ec1"
            ],
            "layout": "IPY_MODEL_5cbdd6142aed47079f8dd02d9dc00d23"
          }
        },
        "b369329812b145fbad34b0e3a00720cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb692c68aff243bd98946d5056a977f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc161ecdfc814da38eb75dadc8566230": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9276d0baa80b48e19a775b1467044e88",
            "max": 1389353,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12032e37d36242808f6960223de2510e",
            "value": 1389353
          }
        },
        "bea016d468ff4c9da7303715fc9588f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "beac7e6851de425d8f57b01118bd90e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3a43c4ea1374a9bad3b3c311ab48778": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_375b00ed46984e7fb26751a8b718c0db",
            "max": 76,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb692c68aff243bd98946d5056a977f9",
            "value": 76
          }
        },
        "c459955c82774374bd6f924dccfb044e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4e168535e87402f9ee61052c27a664a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd80f4ada5ae4e2baa5b3d6154c09f66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc10fe5f3326447fb9e742d44912f086",
              "IPY_MODEL_53e13e7815d94c34b579e8568e6375c0",
              "IPY_MODEL_fe404c2bf46e4327895d401114a89294"
            ],
            "layout": "IPY_MODEL_3bad5d0c59804481bfd7cf1b29f3129a"
          }
        },
        "d1900b43caeb4304bd7a77d9ea26bf0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7a852405cb9a4798a75cabf43aa1dab3",
              "IPY_MODEL_c3a43c4ea1374a9bad3b3c311ab48778",
              "IPY_MODEL_e9695d9c2d49410b9a69fed589f28aba"
            ],
            "layout": "IPY_MODEL_8f75f7643252428ba2f81f2f405d453c"
          }
        },
        "d1a54dd2fd074a74b1c8710db2db3b69": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d270f09a384c4b63b17bec9281cc57a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d84f667aca6c4179a930fb24b00269e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8f05ef6ab454921ba0fb3f155ad2465": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbc06cefa88e4a968c2b0ec9a9841cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaa5140041a9414a9c1fe1ce91ba298a",
            "placeholder": "​",
            "style": "IPY_MODEL_fad68e9a9d004e30aed551a0aea7f66d",
            "value": "config.json: 100%"
          }
        },
        "dc10fe5f3326447fb9e742d44912f086": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90588558ea724f4590939d4e3722bc65",
            "placeholder": "​",
            "style": "IPY_MODEL_308f57eb67ff485789982a5b8e5946de",
            "value": "model.safetensors: 100%"
          }
        },
        "e473108aa2fa4bbc8a7b7c1452e0a299": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9695d9c2d49410b9a69fed589f28aba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a885f8682d3c4309ba7c27e9b466eded",
            "placeholder": "​",
            "style": "IPY_MODEL_c4e168535e87402f9ee61052c27a664a",
            "value": " 76/76 [06:30&lt;00:00,  4.24s/it]"
          }
        },
        "ed63cadc2bd24f2a830710a28b1eb22c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d270f09a384c4b63b17bec9281cc57a3",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1611b5cb7d52425b9bc6beb0969adf2f",
            "value": 147
          }
        },
        "edd94167ca484b5baa93d3e272f92141": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08632020ac154eeea23e170454e0b959",
              "IPY_MODEL_9fd4862163c843989eaa8b38e6042c3e",
              "IPY_MODEL_1f144892695c488e938599a88cb83fb7"
            ],
            "layout": "IPY_MODEL_fb8cf0da2a11411ba4d082817e32034c"
          }
        },
        "f14a8378ab87457086fe2f4a7861a110": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7967e664c6d4fc6ae879a7d9d93e2b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7eec62138654512b041ab2ef917deaf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f83002e813f94a16b58e49d2e0d33eb7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fad68e9a9d004e30aed551a0aea7f66d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb8cf0da2a11411ba4d082817e32034c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd073a9d053e43a0a88c337e3927a232": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd45b722101340768dac9f7106b301b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe404c2bf46e4327895d401114a89294": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0771b9a98bb408bb30f54066160c1f5",
            "placeholder": "​",
            "style": "IPY_MODEL_1ca6a08f443d4539b56c7f341f040695",
            "value": " 242M/242M [00:00&lt;00:00, 345MB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
